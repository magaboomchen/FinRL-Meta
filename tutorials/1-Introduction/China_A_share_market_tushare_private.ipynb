{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "-G6H6HsRTFLn",
   "metadata": {
    "id": "-G6H6HsRTFLn"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Meta/blob/master/tutorials/1-Introduction/China_A_share_market_tushare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ShYRMdBTFLp",
   "metadata": {
    "id": "3ShYRMdBTFLp"
   },
   "source": [
    "## Quantitative trading in China A stock market with FinRL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pBU3DdPFTFLp",
   "metadata": {
    "id": "pBU3DdPFTFLp"
   },
   "source": [
    "Install FinRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51W37k2_TFLq",
   "metadata": {
    "id": "51W37k2_TFLq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ZmuaPTCTFLr",
   "metadata": {
    "id": "9ZmuaPTCTFLr"
   },
   "source": [
    "Install other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "q6T3o9yTTFLr",
   "metadata": {
    "id": "q6T3o9yTTFLr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install stockstats\n",
    "# !pip install tushare\n",
    "# #install talib\n",
    "# !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz \n",
    "# !tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "# import os\n",
    "# os.chdir('ta-lib') \n",
    "# !./configure --prefix=/usr\n",
    "# !make\n",
    "# !make install\n",
    "# #!sudo make install # Sometimes it need root \n",
    "# os.chdir('../')\n",
    "# !pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "DrReji1OTFLr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrReji1OTFLr",
    "outputId": "325c38e3-ca71-4b58-e0be-104e15011fe2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %cd /\n",
    "# !git clone https://github.com/AI4Finance-Foundation/FinRL-Meta\n",
    "# %cd /FinRL-Meta/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C-MYxgpJTMGP",
   "metadata": {
    "id": "C-MYxgpJTMGP"
   },
   "source": [
    "##Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Vx_hcZwgTKQp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vx_hcZwgTKQp",
    "outputId": "d6b36801-3064-4251-aadd-2396cb03ad5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL Modules have been imported!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "\n",
    "display.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from typing import List\n",
    "\n",
    "import pyfolio\n",
    "from pyfolio import timeseries\n",
    "\n",
    "from main import check_and_make_directories\n",
    "from meta import config\n",
    "from meta.config import (ALPACA_API_BASE_URL, ALPACA_API_KEY,\n",
    "                         ALPACA_API_SECRET, DATA_SAVE_DIR, ERL_PARAMS,\n",
    "                         INDICATORS, RESULTS_DIR, SAC_PARAMS,\n",
    "                         TENSORBOARD_LOG_DIR, TEST_END_DATE, TEST_START_DATE,\n",
    "                         TRADE_END_DATE, TRADE_START_DATE, TRAIN_END_DATE,\n",
    "                         TRAIN_START_DATE, TRAINED_MODEL_DIR, RLlib_PARAMS)\n",
    "from meta.config_tickers import DOW_30_TICKER\n",
    "from meta.data_processor import DataProcessor\n",
    "from meta.data_processors.tushare import ReturnPlotter, Tushare\n",
    "from meta.data_processors.tushare_private import ReturnPlotterPrivate\n",
    "from meta.env_stock_trading.env_stocktrading_China_A_shares import \\\n",
    "    StockTradingEnv\n",
    "from meta.local.agents.stablebaselines3_models_private import DRLAgentPrivate\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "print(\"ALL Modules have been imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FRQz2ptSTjPJ",
   "metadata": {
    "id": "FRQz2ptSTjPJ"
   },
   "source": [
    "##Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pmttRZWWTXcd",
   "metadata": {
    "id": "pmttRZWWTXcd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' \n",
    "use check_and_make_directories() to replace the following\n",
    "\n",
    "if not os.path.exists(\"./datasets\"): \n",
    "  os.makedirs(\"./datasets\") \n",
    "if not os.path.exists(\"./trained_models\"): \n",
    "  os.makedirs(\"./trained_models\") \n",
    "if not os.path.exists(\"./tensorboard_log\"): \n",
    "  os.makedirs(\"./tensorboard_log\") \n",
    "if not os.path.exists(\"./results\"): \n",
    "  os.makedirs(\"./results\") \n",
    "'''\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94s2JtmxTuLq",
   "metadata": {
    "id": "94s2JtmxTuLq"
   },
   "source": [
    "##Download data, cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "xpPTz-xDTovy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpPTz-xDTovy",
    "outputId": "40df5f90-6211-452c-ee63-2dc2c849b370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tushare successfully connected\n"
     ]
    }
   ],
   "source": [
    "ticker_list = ['600000.SH', '600009.SH', '600016.SH', '600028.SH', '600030.SH', '600031.SH', '600036.SH', '600050.SH', '600104.SH', '600196.SH', '600276.SH', '600309.SH', '600519.SH', '600547.SH', '600570.SH']\n",
    "\n",
    "TRAIN_START_DATE = '2015-01-01' \n",
    "TRAIN_END_DATE= '2019-08-01' \n",
    "TRADE_START_DATE = '2019-08-01' \n",
    "TRADE_END_DATE = '2020-01-03'\n",
    "\n",
    "TIME_INTERVAL = \"1d\" \n",
    "kwargs = {} \n",
    "kwargs['token'] = '27080ec403c0218f96f388bca1b1d85329d563c91a43672239619ef5'\n",
    "p = DataProcessor(data_source='tushare', start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, time_interval=TIME_INTERVAL, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "svZh2OT0T7PG",
   "metadata": {
    "id": "svZh2OT0T7PG"
   },
   "source": [
    "###Download and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "v_PzruLIT3D1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_PzruLIT3D1",
    "outputId": "fa4b9030-f8ff-41a3-abef-77be4f9d37ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:14<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (17960, 8)\n",
      "Shape of DataFrame:  (18315, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p.download_data(ticker_list=ticker_list)\n",
    "\n",
    "p.clean_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tsHu-XT_T_vQ",
   "metadata": {
    "id": "tsHu-XT_T_vQ"
   },
   "source": [
    "###Add technical indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "VfniyyQQT3nq",
   "metadata": {
    "id": "VfniyyQQT3nq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Shape of DataFrame:  (18270, 17)\n"
     ]
    }
   ],
   "source": [
    "p.add_technical_indicator(config.INDICATORS) \n",
    "p.clean_data()\n",
    "\n",
    "#print(f\"p.dataframe: {p.dataframe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cKZk3jGuUR34",
   "metadata": {
    "id": "cKZk3jGuUR34"
   },
   "source": [
    "##Split training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "SuKbrwflUVeU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuKbrwflUVeU",
    "outputId": "7596367b-670d-4d6c-b439-033075d87589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train.tic.unique()): 15\n"
     ]
    }
   ],
   "source": [
    "train = p.data_split(p.dataframe, TRAIN_START_DATE, TRAIN_END_DATE) \n",
    "\n",
    "print(f\"len(train.tic.unique()): {len(train.tic.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ONAnSMBUWyu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ONAnSMBUWyu",
    "outputId": "5bdf45d0-7689-4d31-dfa6-cbcbe8e64827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.tic.unique(): ['600000.SH' '600009.SH' '600016.SH' '600028.SH' '600030.SH' '600031.SH'\n",
      " '600036.SH' '600050.SH' '600104.SH' '600196.SH' '600276.SH' '600309.SH'\n",
      " '600519.SH' '600547.SH' '600570.SH']\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.tic.unique(): {train.tic.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "BXF8hYDvUXfv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXF8hYDvUXfv",
    "outputId": "a08ebe19-0107-4e31-c6df-816c846aa3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.head():          tic        date  index   open   high    low  close      volume  day  \\\n",
      "0  600000.SH  2015-01-08     45  15.87  15.88  15.20  15.25  3306271.72  3.0   \n",
      "0  600009.SH  2015-01-08     46  20.18  20.18  19.73  20.00   198117.45  3.0   \n",
      "0  600016.SH  2015-01-08     47  10.61  10.66  10.09  10.20  4851684.17  3.0   \n",
      "0  600028.SH  2015-01-08     48   7.09   7.41   6.83   6.85  8190902.35  3.0   \n",
      "0  600030.SH  2015-01-08     49  36.40  36.70  34.68  35.25  6376268.69  3.0   \n",
      "\n",
      "       macd    boll_ub    boll_lb     rsi_30      cci_30       dx_30  \\\n",
      "0 -0.032571  16.617911  15.012089   6.058641 -125.593009   23.014040   \n",
      "0 -0.016008  20.663897  19.736103  12.828915  -90.842491  100.000000   \n",
      "0 -0.018247  10.957604   9.997396  11.862558  -99.887006  100.000000   \n",
      "0 -0.008227   7.342000   6.743000  27.409248   36.578171   64.934862   \n",
      "0  0.032910  36.576444  33.808556  61.517448   47.947020  100.000000   \n",
      "\n",
      "   close_30_sma  close_60_sma  \n",
      "0       15.8150       15.8150  \n",
      "0       20.2000       20.2000  \n",
      "0       10.4775       10.4775  \n",
      "0        7.0425        7.0425  \n",
      "0       35.1925       35.1925  \n"
     ]
    }
   ],
   "source": [
    "print(f\"train.head(): {train.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "CnwNoBG5UXSQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnwNoBG5UXSQ",
    "outputId": "3bcf1c7a-e9de-4b92-fc7e-069904d9e6e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (16695, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.shape: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joNhXi_ZUXId",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joNhXi_ZUXId",
    "outputId": "460b9763-6b0f-4976-f772-4a9a7cda2255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 15, State Space: 151\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique()) \n",
    "state_space = stock_dimension * (len(config.INDICATORS) + 2) + 1 \n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "le09273cUmzH",
   "metadata": {
    "id": "le09273cUmzH"
   },
   "source": [
    "##Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Npwpqkr7UpFF",
   "metadata": {
    "id": "Npwpqkr7UpFF"
   },
   "outputs": [],
   "source": [
    "env_kwargs = { \"stock_dim\": stock_dimension, \"hmax\": 1000, \"initial_amount\": 1000000, \"buy_cost_pct\": 6.87e-5, \"sell_cost_pct\": 1.0687e-3, \"reward_scaling\": 1e-4, \"state_space\": state_space, \"action_space\": stock_dimension, \"tech_indicator_list\": config.INDICATORS, \"print_verbosity\": 1, \"initial_buy\": True, \"hundred_each_trade\": True }\n",
    "\n",
    "e_train_gym = StockTradingEnv(df=train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1POZL3nUyDY",
   "metadata": {
    "id": "f1POZL3nUyDY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "print(type(env_train)): None\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env() \n",
    "\n",
    "print(f\"print(type(env_train)): {print(type(env_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QkY8sVWhU6PH",
   "metadata": {
    "id": "QkY8sVWhU6PH"
   },
   "source": [
    "###DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dLjEviBhUzuc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLjEviBhUzuc",
    "outputId": "58226aaa-41dc-45ce-9f5c-1e5cb94d27a4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DRLAgentPrivate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mDRLAgentPrivate\u001b[49m(env\u001b[38;5;241m=\u001b[39menv_train) \n\u001b[1;32m      2\u001b[0m DDPG_PARAMS \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m256\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuffer_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.0005\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_noise\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m} \n\u001b[1;32m      3\u001b[0m POLICY_KWARGS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(net_arch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(pi\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m], qf\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m300\u001b[39m])) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'DRLAgentPrivate' is not defined"
     ]
    }
   ],
   "source": [
    "agent = DRLAgentPrivate(env=env_train) \n",
    "DDPG_PARAMS = { \"batch_size\": 256, \"buffer_size\": 50000, \"learning_rate\": 0.0005, \"action_noise\": \"normal\", \"device\":\"cuda\"} \n",
    "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300])) \n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs=DDPG_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
    "\n",
    "trained_ddpg = agent.train_model(model=model_ddpg, tb_log_name='ddpg', total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ALJ1gqVmVEiU",
   "metadata": {
    "id": "ALJ1gqVmVEiU"
   },
   "source": [
    "###A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2F5qCGnNUzm7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2F5qCGnNUzm7",
    "outputId": "b8db239f-7d37-4587-c511-0f2dc4c6f273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_2\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | 0.217       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.541       |\n",
      "|    reward             | -0.45265964 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.63        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 256       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.4     |\n",
      "|    explained_variance | 0.14      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 82.4      |\n",
      "|    reward             | 3.5806565 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 18.8      |\n",
      "-------------------------------------\n",
      "Episode: 12\n",
      "day: 1112, episode: 12\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1771769.07\n",
      "total_reward: 771769.07\n",
      "total_cost: 101849.08\n",
      "total_trades: 16667\n",
      "Sharpe: 0.614\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 252         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | -0.344      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 13.4        |\n",
      "|    reward             | -0.82781714 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 249        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 8          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -176       |\n",
      "|    reward             | 0.26618448 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 86.4       |\n",
      "--------------------------------------\n",
      "Episode: 13\n",
      "day: 1112, episode: 13\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1766064.30\n",
      "total_reward: 766064.30\n",
      "total_cost: 92070.70\n",
      "total_trades: 16672\n",
      "Sharpe: 0.620\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 247        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.4      |\n",
      "|    explained_variance | 0.00648    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 31.9       |\n",
      "|    reward             | -3.1691675 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.78       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 247        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.4      |\n",
      "|    explained_variance | -0.127     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -15.9      |\n",
      "|    reward             | -1.3254027 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.36       |\n",
      "--------------------------------------\n",
      "Episode: 14\n",
      "day: 1112, episode: 14\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1528926.02\n",
      "total_reward: 528926.02\n",
      "total_cost: 85881.98\n",
      "total_trades: 16669\n",
      "Sharpe: 0.502\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 247        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.5      |\n",
      "|    explained_variance | 0.0251     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -75.1      |\n",
      "|    reward             | -1.0188745 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 20         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 246       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.5     |\n",
      "|    explained_variance | -1.49     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -10.3     |\n",
      "|    reward             | 0.4798833 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.576     |\n",
      "-------------------------------------\n",
      "Episode: 15\n",
      "day: 1112, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 317390.37\n",
      "total_reward: -682609.63\n",
      "total_cost: 61648.63\n",
      "total_trades: 16664\n",
      "Sharpe: -0.274\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 246        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.5      |\n",
      "|    explained_variance | -0.349     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 43.1       |\n",
      "|    reward             | -1.3154677 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 5.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 246        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.5      |\n",
      "|    explained_variance | -0.0396    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 15.7       |\n",
      "|    reward             | -0.9482115 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1          |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 248        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.6      |\n",
      "|    explained_variance | 0.0739     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 9.66       |\n",
      "|    reward             | -1.4963306 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.2        |\n",
      "--------------------------------------\n",
      "Episode: 16\n",
      "day: 1112, episode: 16\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1100231.74\n",
      "total_reward: 100231.74\n",
      "total_cost: 73317.26\n",
      "total_trades: 16665\n",
      "Sharpe: 0.237\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 249       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.6     |\n",
      "|    explained_variance | 0.223     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -37.4     |\n",
      "|    reward             | 0.9794898 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.15      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 250         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | 0.0592      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 9.3         |\n",
      "|    reward             | -0.88692695 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 9.95        |\n",
      "---------------------------------------\n",
      "Episode: 17\n",
      "day: 1112, episode: 17\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1237439.20\n",
      "total_reward: 237439.20\n",
      "total_cost: 76532.80\n",
      "total_trades: 16668\n",
      "Sharpe: 0.313\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 251         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | -0.197      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -3.71       |\n",
      "|    reward             | -0.33813658 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.0521      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 252         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.7       |\n",
      "|    explained_variance | 0.00232     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | -20.3       |\n",
      "|    reward             | -0.25645807 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "Episode: 18\n",
      "day: 1112, episode: 18\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1145726.59\n",
      "total_reward: 145726.59\n",
      "total_cost: 77210.41\n",
      "total_trades: 16674\n",
      "Sharpe: 0.249\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 253        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 31         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.7      |\n",
      "|    explained_variance | 0.0334     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 50.2       |\n",
      "|    reward             | -0.9928699 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 254        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.7      |\n",
      "|    explained_variance | -0.196     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -78.4      |\n",
      "|    reward             | 0.32071263 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 19.6       |\n",
      "--------------------------------------\n",
      "Episode: 19\n",
      "day: 1112, episode: 19\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000043.91\n",
      "total_reward: 43.91\n",
      "total_cost: 74062.09\n",
      "total_trades: 16674\n",
      "Sharpe: 0.136\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 254        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 35         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.7      |\n",
      "|    explained_variance | -0.383     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 98.5       |\n",
      "|    reward             | 0.88596183 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 19.3       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 255      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -21.7    |\n",
      "|    explained_variance | 0.036    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 43.9     |\n",
      "|    reward             | 3.648851 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 13.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 254         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.7       |\n",
      "|    explained_variance | 0.205       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 72.9        |\n",
      "|    reward             | -0.15894403 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 10.5        |\n",
      "---------------------------------------\n",
      "Episode: 20\n",
      "day: 1112, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1180995.92\n",
      "total_reward: 180995.92\n",
      "total_cost: 57327.08\n",
      "total_trades: 16669\n",
      "Sharpe: 0.276\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 255       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.7     |\n",
      "|    explained_variance | 0.716     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 7.27      |\n",
      "|    reward             | -0.686569 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.145     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 255        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 43         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.8      |\n",
      "|    explained_variance | -0.29      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 18.6       |\n",
      "|    reward             | -0.7798069 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 1.6        |\n",
      "--------------------------------------\n",
      "Episode: 21\n",
      "day: 1112, episode: 21\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1167190.39\n",
      "total_reward: 167190.39\n",
      "total_cost: 76298.61\n",
      "total_trades: 16672\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 256         |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 4.74        |\n",
      "|    reward             | -0.15693359 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 256        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.8      |\n",
      "|    explained_variance | -0.0278    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | 69.8       |\n",
      "|    reward             | -1.6785927 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 17.4       |\n",
      "--------------------------------------\n",
      "Episode: 22\n",
      "day: 1112, episode: 22\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1173595.95\n",
      "total_reward: 173595.95\n",
      "total_cost: 76604.05\n",
      "total_trades: 16673\n",
      "Sharpe: 0.281\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 257        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.9      |\n",
      "|    explained_variance | -0.683     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | 14.8       |\n",
      "|    reward             | -1.8222178 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.604      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 257        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.9      |\n",
      "|    explained_variance | -0.0513    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 83.5       |\n",
      "|    reward             | -1.9105335 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 15.4       |\n",
      "--------------------------------------\n",
      "Episode: 23\n",
      "day: 1112, episode: 23\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1245924.42\n",
      "total_reward: 245924.42\n",
      "total_cost: 51664.58\n",
      "total_trades: 16673\n",
      "Sharpe: 0.384\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 257       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22       |\n",
      "|    explained_variance | -0.0394   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 95.7      |\n",
      "|    reward             | 1.8144269 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 21.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 258        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 54         |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | 0.508      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | 8.82       |\n",
      "|    reward             | 0.02461306 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.192      |\n",
      "--------------------------------------\n",
      "Episode: 24\n",
      "day: 1112, episode: 24\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1075589.65\n",
      "total_reward: 75589.65\n",
      "total_cost: 61587.35\n",
      "total_trades: 16675\n",
      "Sharpe: 0.186\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 258      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -22.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 21.3     |\n",
      "|    reward             | 0.458021 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 258       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.1     |\n",
      "|    explained_variance | 0.0293    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 54.7      |\n",
      "|    reward             | 0.5741241 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 9.25      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 258        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | -11.1      |\n",
      "|    reward             | 0.37689808 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.512      |\n",
      "--------------------------------------\n",
      "Episode: 25\n",
      "day: 1112, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1854285.11\n",
      "total_reward: 854285.11\n",
      "total_cost: 71121.89\n",
      "total_trades: 16673\n",
      "Sharpe: 0.637\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 259         |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | 1.44        |\n",
      "|    reward             | 0.027704207 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 259        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.2      |\n",
      "|    explained_variance | -0.0262    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | -180       |\n",
      "|    reward             | -3.8489556 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 73.5       |\n",
      "--------------------------------------\n",
      "Episode: 26\n",
      "day: 1112, episode: 26\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1136652.79\n",
      "total_reward: 136652.79\n",
      "total_cost: 56582.21\n",
      "total_trades: 16675\n",
      "Sharpe: 0.242\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 259        |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | 21.7       |\n",
      "|    reward             | 0.22922674 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.973      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 259          |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 67           |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | -1.25        |\n",
      "|    reward             | -0.014478387 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.00627      |\n",
      "----------------------------------------\n",
      "Episode: 27\n",
      "day: 1112, episode: 27\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 760501.04\n",
      "total_reward: -239498.96\n",
      "total_cost: 42323.96\n",
      "total_trades: 16676\n",
      "Sharpe: -0.444\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 260         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | 2.52        |\n",
      "|    reward             | 0.042390697 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.0158      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 260         |\n",
      "|    iterations         | 3700        |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 18500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.5       |\n",
      "|    explained_variance | 0.0266      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3699        |\n",
      "|    policy_loss        | -25.8       |\n",
      "|    reward             | -0.13098648 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 7.57        |\n",
      "---------------------------------------\n",
      "Episode: 28\n",
      "day: 1112, episode: 28\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1852733.20\n",
      "total_reward: 852733.20\n",
      "total_cost: 40768.80\n",
      "total_trades: 16675\n",
      "Sharpe: 0.816\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 260       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.5     |\n",
      "|    explained_variance | 0.00511   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 25.9      |\n",
      "|    reward             | 0.5689266 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 2.57      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 260       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 6.2       |\n",
      "|    reward             | 3.7346244 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 6.03      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 260        |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.6      |\n",
      "|    explained_variance | -0.0695    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | -33.1      |\n",
      "|    reward             | 0.34995967 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 1.99       |\n",
      "--------------------------------------\n",
      "Episode: 29\n",
      "day: 1112, episode: 29\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1882312.14\n",
      "total_reward: 882312.14\n",
      "total_cost: 46891.86\n",
      "total_trades: 16677\n",
      "Sharpe: 0.689\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 260         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | -1.17       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 20.3        |\n",
      "|    reward             | -0.47573948 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 261        |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 80         |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.6      |\n",
      "|    explained_variance | 0.0213     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | -24.2      |\n",
      "|    reward             | -1.0089326 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 1.37       |\n",
      "--------------------------------------\n",
      "Episode: 30\n",
      "day: 1112, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 758065.15\n",
      "total_reward: -241934.85\n",
      "total_cost: 40448.85\n",
      "total_trades: 16675\n",
      "Sharpe: -0.149\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 261        |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 82         |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.6      |\n",
      "|    explained_variance | 0.287      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | -36.4      |\n",
      "|    reward             | -1.2480487 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 3.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.7     |\n",
      "|    explained_variance | 0.0127    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -5.38     |\n",
      "|    reward             | 2.6727967 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.4       |\n",
      "-------------------------------------\n",
      "Episode: 31\n",
      "day: 1112, episode: 31\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1220818.28\n",
      "total_reward: 220818.28\n",
      "total_cost: 66172.72\n",
      "total_trades: 16669\n",
      "Sharpe: 0.302\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.7       |\n",
      "|    explained_variance | -0.0169     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | -40.3       |\n",
      "|    reward             | -0.86674595 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 3.95        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 261        |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 87         |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.7      |\n",
      "|    explained_variance | 0.00361    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | 1.27       |\n",
      "|    reward             | -0.9016009 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 2.31       |\n",
      "--------------------------------------\n",
      "Episode: 32\n",
      "day: 1112, episode: 32\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1247099.97\n",
      "total_reward: 247099.97\n",
      "total_cost: 74520.03\n",
      "total_trades: 16671\n",
      "Sharpe: 0.317\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.7     |\n",
      "|    explained_variance | -0.0126   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -33.3     |\n",
      "|    reward             | 1.8169909 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 36.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.7     |\n",
      "|    explained_variance | -0.774    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 66.9      |\n",
      "|    reward             | 0.4461789 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 8.81      |\n",
      "-------------------------------------\n",
      "Episode: 33\n",
      "day: 1112, episode: 33\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1074121.74\n",
      "total_reward: 74121.74\n",
      "total_cost: 66557.26\n",
      "total_trades: 16668\n",
      "Sharpe: 0.213\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 261         |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4899        |\n",
      "|    policy_loss        | 6.48        |\n",
      "|    reward             | -0.34405416 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.7     |\n",
      "|    explained_variance | -0.0486   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 69.6      |\n",
      "|    reward             | 0.7208759 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 11.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.7     |\n",
      "|    explained_variance | 0.0104    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 105       |\n",
      "|    reward             | -6.518748 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 41.1      |\n",
      "-------------------------------------\n",
      "Episode: 34\n",
      "day: 1112, episode: 34\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1082888.84\n",
      "total_reward: 82888.84\n",
      "total_cost: 43906.16\n",
      "total_trades: 16674\n",
      "Sharpe: 0.219\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.7     |\n",
      "|    explained_variance | -0.364    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -34.7     |\n",
      "|    reward             | 0.6321545 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 2.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.7     |\n",
      "|    explained_variance | 0.172     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 40.6      |\n",
      "|    reward             | 2.1608183 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 4.8       |\n",
      "-------------------------------------\n",
      "Episode: 35\n",
      "day: 1112, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1439331.67\n",
      "total_reward: 439331.67\n",
      "total_cost: 38085.33\n",
      "total_trades: 16678\n",
      "Sharpe: 0.415\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 262        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | -23.3      |\n",
      "|    reward             | 0.82040554 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 1.19       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 262        |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 104        |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.8      |\n",
      "|    explained_variance | -0.0421    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | -127       |\n",
      "|    reward             | -1.0288275 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 34.2       |\n",
      "--------------------------------------\n",
      "Episode: 36\n",
      "day: 1112, episode: 36\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 892026.67\n",
      "total_reward: -107973.33\n",
      "total_cost: 15638.33\n",
      "total_trades: 16670\n",
      "Sharpe: 0.121\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 262        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 106        |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.8      |\n",
      "|    explained_variance | 0.0707     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | -20.6      |\n",
      "|    reward             | -0.4170135 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 3.05       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 262        |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 108        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.7      |\n",
      "|    explained_variance | 0.0604     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | 16.6       |\n",
      "|    reward             | -0.1997377 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 1.49       |\n",
      "--------------------------------------\n",
      "Episode: 37\n",
      "day: 1112, episode: 37\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1157023.32\n",
      "total_reward: 157023.32\n",
      "total_cost: 38600.68\n",
      "total_trades: 16669\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 262        |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 110        |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.7      |\n",
      "|    explained_variance | 0.116      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | 80.4       |\n",
      "|    reward             | 0.15529281 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 15         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 262         |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.7       |\n",
      "|    explained_variance | -0.728      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | -14.3       |\n",
      "|    reward             | -0.04117786 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.429       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 114       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.7     |\n",
      "|    explained_variance | -0.0982   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -25.1     |\n",
      "|    reward             | 1.8248823 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 3.63      |\n",
      "-------------------------------------\n",
      "Episode: 38\n",
      "day: 1112, episode: 38\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 919845.58\n",
      "total_reward: -80154.42\n",
      "total_cost: 38701.42\n",
      "total_trades: 16675\n",
      "Sharpe: 0.108\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 262        |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 116        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | 19.7       |\n",
      "|    reward             | 0.35281187 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.902      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 262        |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 117        |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.9      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | -10.1      |\n",
      "|    reward             | 0.18181583 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.238      |\n",
      "--------------------------------------\n",
      "Episode: 39\n",
      "day: 1112, episode: 39\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 653533.14\n",
      "total_reward: -346466.86\n",
      "total_cost: 43567.86\n",
      "total_trades: 16672\n",
      "Sharpe: -0.303\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 262          |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 119          |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.9        |\n",
      "|    explained_variance | -0.174       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | -0.0534      |\n",
      "|    reward             | -0.071461976 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 6.13         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 262        |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 121        |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.9      |\n",
      "|    explained_variance | -0.571     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | 26.2       |\n",
      "|    reward             | -2.8956099 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 2.97       |\n",
      "--------------------------------------\n",
      "Episode: 40\n",
      "day: 1112, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1266386.96\n",
      "total_reward: 266386.96\n",
      "total_cost: 59686.04\n",
      "total_trades: 16673\n",
      "Sharpe: 0.331\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 262        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.9      |\n",
      "|    explained_variance | 0.021      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | -137       |\n",
      "|    reward             | -2.5225394 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 54.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.9      |\n",
      "|    explained_variance | -0.504     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -70.1      |\n",
      "|    reward             | -1.2279112 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 9.26       |\n",
      "--------------------------------------\n",
      "Episode: 41\n",
      "day: 1112, episode: 41\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 864013.04\n",
      "total_reward: -135986.96\n",
      "total_cost: 54521.96\n",
      "total_trades: 16675\n",
      "Sharpe: 0.149\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 263         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.9       |\n",
      "|    explained_variance | -0.0708     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -293        |\n",
      "|    reward             | -0.64570594 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 206         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 129        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.9      |\n",
      "|    explained_variance | -0.556     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | -44.2      |\n",
      "|    reward             | 0.76654685 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 4.08       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 263         |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.9       |\n",
      "|    explained_variance | 0.0582      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | -38.9       |\n",
      "|    reward             | -0.40204522 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 3.43        |\n",
      "---------------------------------------\n",
      "Episode: 42\n",
      "day: 1112, episode: 42\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1094922.64\n",
      "total_reward: 94922.64\n",
      "total_cost: 50215.36\n",
      "total_trades: 16658\n",
      "Sharpe: 0.253\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 132        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23        |\n",
      "|    explained_variance | -0.509     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 0.0296     |\n",
      "|    reward             | -0.4781429 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.0283     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23        |\n",
      "|    explained_variance | 0.637      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | -0.522     |\n",
      "|    reward             | 0.29001066 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.00618    |\n",
      "--------------------------------------\n",
      "Episode: 43\n",
      "day: 1112, episode: 43\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 807657.63\n",
      "total_reward: -192342.37\n",
      "total_cost: 52666.37\n",
      "total_trades: 16675\n",
      "Sharpe: 0.032\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | 2.38         |\n",
      "|    reward             | -0.021651391 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.0159       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 138        |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | -3.85      |\n",
      "|    reward             | 0.17642316 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.0317     |\n",
      "--------------------------------------\n",
      "Episode: 44\n",
      "day: 1112, episode: 44\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 910201.74\n",
      "total_reward: -89798.26\n",
      "total_cost: 25548.26\n",
      "total_trades: 16679\n",
      "Sharpe: -0.180\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 140        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 3.92       |\n",
      "|    reward             | 0.32371578 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 0.0963     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 142        |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | 8.67       |\n",
      "|    reward             | 0.79006594 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.262      |\n",
      "--------------------------------------\n",
      "Episode: 45\n",
      "day: 1112, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 973281.03\n",
      "total_reward: -26718.97\n",
      "total_cost: 28215.97\n",
      "total_trades: 16677\n",
      "Sharpe: 0.101\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 263       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.5     |\n",
      "|    explained_variance | -0.14     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -164      |\n",
      "|    reward             | 1.7855268 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 51.9      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | -4.23        |\n",
      "|    reward             | -0.104714654 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 0.0379       |\n",
      "----------------------------------------\n",
      "Episode: 46\n",
      "day: 1112, episode: 46\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 986679.31\n",
      "total_reward: -13320.69\n",
      "total_cost: 30743.69\n",
      "total_trades: 16676\n",
      "Sharpe: 0.139\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 263       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 0.0297    |\n",
      "|    reward             | -0.734376 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.0622    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | -0.819       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | -14.9        |\n",
      "|    reward             | -0.016801124 |\n",
      "|    std                | 1.18         |\n",
      "|    value_loss         | 0.497        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 263         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 1.01        |\n",
      "|    reward             | 0.026485657 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 0.0716      |\n",
      "---------------------------------------\n",
      "Episode: 47\n",
      "day: 1112, episode: 47\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 966957.30\n",
      "total_reward: -33042.70\n",
      "total_cost: 29666.70\n",
      "total_trades: 16679\n",
      "Sharpe: 0.091\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 153        |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | 15.7       |\n",
      "|    reward             | 0.16310889 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 0.648      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -12.5      |\n",
      "|    reward             | -0.3534082 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 0.346      |\n",
      "--------------------------------------\n",
      "Episode: 48\n",
      "day: 1112, episode: 48\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 972769.70\n",
      "total_reward: -27230.30\n",
      "total_cost: 20667.30\n",
      "total_trades: 16673\n",
      "Sharpe: -0.123\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 264        |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 1.04       |\n",
      "|    reward             | 0.07007391 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 0.00164    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 264          |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 159          |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | -1.28        |\n",
      "|    reward             | -0.074564844 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 0.00565      |\n",
      "----------------------------------------\n",
      "Episode: 49\n",
      "day: 1112, episode: 49\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 926557.82\n",
      "total_reward: -73442.18\n",
      "total_cost: 24436.18\n",
      "total_trades: 16677\n",
      "Sharpe: -0.226\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 264           |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 160           |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.5         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8499          |\n",
      "|    policy_loss        | 103           |\n",
      "|    reward             | -0.0005997227 |\n",
      "|    std                | 1.24          |\n",
      "|    value_loss         | 19.1          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8599        |\n",
      "|    policy_loss        | 12.8        |\n",
      "|    reward             | -0.11194604 |\n",
      "|    std                | 1.25        |\n",
      "|    value_loss         | 0.427       |\n",
      "---------------------------------------\n",
      "Episode: 50\n",
      "day: 1112, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 856224.11\n",
      "total_reward: -143775.89\n",
      "total_cost: 43829.89\n",
      "total_trades: 16676\n",
      "Sharpe: -0.166\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 264        |\n",
      "|    iterations         | 8700       |\n",
      "|    time_elapsed       | 164        |\n",
      "|    total_timesteps    | 43500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8699       |\n",
      "|    policy_loss        | 8.66       |\n",
      "|    reward             | -3.0809712 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 0.236      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | 0.0358      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -12.6       |\n",
      "|    reward             | -0.98157805 |\n",
      "|    std                | 1.25        |\n",
      "|    value_loss         | 3.03        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 264        |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 168        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | 25.3       |\n",
      "|    reward             | -3.1432838 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 35.4       |\n",
      "--------------------------------------\n",
      "Episode: 51\n",
      "day: 1112, episode: 51\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1330514.91\n",
      "total_reward: 330514.91\n",
      "total_cost: 56193.09\n",
      "total_trades: 16674\n",
      "Sharpe: 0.396\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | -0.0419     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -52.8       |\n",
      "|    reward             | -0.79782027 |\n",
      "|    std                | 1.25        |\n",
      "|    value_loss         | 6.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | -0.13303563 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "Episode: 52\n",
      "day: 1112, episode: 52\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1159858.36\n",
      "total_reward: 159858.36\n",
      "total_cost: 39140.64\n",
      "total_trades: 16678\n",
      "Sharpe: 0.260\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -24.7     |\n",
      "|    explained_variance | -0.0234   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 184       |\n",
      "|    reward             | 5.0897527 |\n",
      "|    std                | 1.26      |\n",
      "|    value_loss         | 59.2      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.8       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -11.1       |\n",
      "|    reward             | -0.38035032 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "Episode: 53\n",
      "day: 1112, episode: 53\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1158982.03\n",
      "total_reward: 158982.03\n",
      "total_cost: 36350.97\n",
      "total_trades: 16678\n",
      "Sharpe: 0.260\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.8       |\n",
      "|    explained_variance | -0.0299     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | -173        |\n",
      "|    reward             | -0.75047445 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 93.9        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | -18.7       |\n",
      "|    reward             | -0.29702815 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 0.781       |\n",
      "---------------------------------------\n",
      "Episode: 54\n",
      "day: 1112, episode: 54\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1547185.01\n",
      "total_reward: 547185.01\n",
      "total_cost: 42091.99\n",
      "total_trades: 16677\n",
      "Sharpe: 0.557\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | -18         |\n",
      "|    reward             | -0.19161244 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | -0.247      |\n",
      "|    reward             | -0.12987478 |\n",
      "|    std                | 1.28        |\n",
      "|    value_loss         | 0.0258      |\n",
      "---------------------------------------\n",
      "Episode: 55\n",
      "day: 1112, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 979687.16\n",
      "total_reward: -20312.84\n",
      "total_cost: 30533.84\n",
      "total_trades: 16678\n",
      "Sharpe: -0.015\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 185         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | -2.84       |\n",
      "|    reward             | 0.021762814 |\n",
      "|    std                | 1.29        |\n",
      "|    value_loss         | 0.115       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 264          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 187          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -12          |\n",
      "|    reward             | -0.005561538 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 0.244        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.2       |\n",
      "|    explained_variance | 0.699       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | 144         |\n",
      "|    reward             | -0.66842854 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 29          |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgentPrivate(env=env_train) \n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c', total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ArAnGULyVVfK",
   "metadata": {
    "id": "ArAnGULyVVfK"
   },
   "source": [
    "##Trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TzU6JBAWVGPG",
   "metadata": {
    "id": "TzU6JBAWVGPG"
   },
   "outputs": [],
   "source": [
    "trade = p.data_split(p.dataframe, TRADE_START_DATE, TRADE_END_DATE) \n",
    "env_kwargs = { \"stock_dim\": stock_dimension, \"hmax\": 1000, \"initial_amount\": 1000000, \"buy_cost_pct\": 6.87e-5, \"sell_cost_pct\": 1.0687e-3, \"reward_scaling\": 1e-4, \"state_space\": state_space, \"action_space\": stock_dimension, \"tech_indicator_list\": config.INDICATORS, \"print_verbosity\": 1, \"initial_buy\": False, \"hundred_each_trade\": True } \n",
    "e_trade_gym = StockTradingEnv(df=trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdg8qypiVSOn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdg8qypiVSOn",
    "outputId": "af6f6967-7e06-41c5-850f-d0e2512ecd43"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DRLAgent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_account_value, df_actions \u001b[38;5;241m=\u001b[39m \u001b[43mDRLAgent\u001b[49m\u001b[38;5;241m.\u001b[39mDRL_prediction(model\u001b[38;5;241m=\u001b[39mtrained_ddpg, environment\u001b[38;5;241m=\u001b[39me_trade_gym)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# import pickle\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# with open('./df_account_value.pickle', 'wb') as handle:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     pickle.dump(df_account_value, handle, protocol=pickle.HIGHEST_PROTOCOL)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DRLAgent' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgentPrivate.DRL_prediction(model=trained_ddpg, environment=e_trade_gym)\n",
    "# import pickle\n",
    "# with open('./df_account_value.pickle', 'wb') as handle:\n",
    "#     pickle.dump(df_account_value, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d82263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  account_value\n",
      "0    2019-08-01   1.000000e+06\n",
      "1    2019-08-02   9.972021e+05\n",
      "2    2019-08-05   9.826644e+05\n",
      "3    2019-08-06   9.825871e+05\n",
      "4    2019-08-07   9.830335e+05\n",
      "..          ...            ...\n",
      "99   2019-12-26   1.120953e+06\n",
      "100  2019-12-27   1.125883e+06\n",
      "101  2019-12-30   1.139063e+06\n",
      "102  2019-12-31   1.151556e+06\n",
      "103  2020-01-02   1.153142e+06\n",
      "\n",
      "[104 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_account_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ih4rdH3uVSo1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ih4rdH3uVSo1",
    "outputId": "291d8234-ee54-4ef2-a511-1e084a783f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_actions:             600000.SH  600009.SH  600016.SH  600028.SH  600030.SH  600031.SH  \\\n",
      "date                                                                           \n",
      "2019-08-01          0       1000       1000          0          0          0   \n",
      "2019-08-02          0       1000       1000          0          0          0   \n",
      "2019-08-05          0       1000       1000          0          0          0   \n",
      "2019-08-06          0        700       1000          0          0          0   \n",
      "2019-08-07          0          0        100          0          0          0   \n",
      "...               ...        ...        ...        ...        ...        ...   \n",
      "2019-12-25          0          0          0          0          0          0   \n",
      "2019-12-26          0          0          0          0          0          0   \n",
      "2019-12-27          0          0          0          0          0          0   \n",
      "2019-12-30          0          0          0          0          0          0   \n",
      "2019-12-31          0          0          0          0          0          0   \n",
      "\n",
      "            600036.SH  600050.SH  600104.SH  600196.SH  600276.SH  600309.SH  \\\n",
      "date                                                                           \n",
      "2019-08-01       1000          0          0       1000       1000       1000   \n",
      "2019-08-02       1000          0          0       1000       1000       1000   \n",
      "2019-08-05       1000          0          0       1000       1000       1000   \n",
      "2019-08-06       1000          0          0       1000       1000       1000   \n",
      "2019-08-07          0          0          0        100          0          0   \n",
      "...               ...        ...        ...        ...        ...        ...   \n",
      "2019-12-25          0          0          0          0          0          0   \n",
      "2019-12-26          0          0          0          0          0          0   \n",
      "2019-12-27          0          0          0          0          0          0   \n",
      "2019-12-30          0          0          0          0          0          0   \n",
      "2019-12-31          0          0          0          0          0          0   \n",
      "\n",
      "            600519.SH  600547.SH  600570.SH  \n",
      "date                                         \n",
      "2019-08-01          0          0          0  \n",
      "2019-08-02          0          0          0  \n",
      "2019-08-05          0          0          0  \n",
      "2019-08-06          0          0          0  \n",
      "2019-08-07          0          0          0  \n",
      "...               ...        ...        ...  \n",
      "2019-12-25          0          0          0  \n",
      "2019-12-26          0          0          0  \n",
      "2019-12-27          0          0          0  \n",
      "2019-12-30          0          0          0  \n",
      "2019-12-31          0          0          0  \n",
      "\n",
      "[103 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "df_actions.to_csv(\"action.csv\", index=False) \n",
    "print(f\"df_actions: {df_actions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l7X1KIaVWUYp",
   "metadata": {
    "id": "l7X1KIaVWUYp"
   },
   "source": [
    "##Backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dUJn8einWPKI",
   "metadata": {
    "id": "dUJn8einWPKI"
   },
   "source": [
    "###matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pR6hNouKWOoY",
   "metadata": {
    "id": "pR6hNouKWOoY"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import meta.data_processors.tushare_private\n",
    "importlib.reload(meta.data_processors.tushare_private)\n",
    "from meta.data_processors.tushare_private import ReturnPlotterPrivate, TICKET_TYPE_INDEX, TICKET_TYPE_TICKET\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plotter = ReturnPlotterPrivate(df_account_value, trade, TRADE_START_DATE, TRADE_END_DATE)\n",
    "plotter.plot(figure_filepath=\"./China_A_share.png\")\n",
    "# plotter.plot()\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qx62Q575YC9I",
   "metadata": {
    "id": "Qx62Q575YC9I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TICKET_TYPE_INDEX\n"
     ]
    }
   ],
   "source": [
    "# ticket: SSE 50：000016.SH\n",
    "baseline_ticket = \"000016.SH\"\n",
    "plotter.plot(baseline_ticket, figure_filepath=\"./China_A_share_vs_{0}.png\".format(baseline_ticket), ticket_type=TICKET_TYPE_INDEX)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XUAh2S9Lamxe",
   "metadata": {
    "id": "XUAh2S9Lamxe"
   },
   "source": [
    "###CSI 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZSRJpKINYcBa",
   "metadata": {
    "id": "ZSRJpKINYcBa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TICKET_TYPE_INDEX\n",
      "baseline_df         ts_code trade_date      close       open       high        low  \\\n",
      "0    399300.SZ   20200103  4144.9649  4161.2185  4164.2989  4131.8640   \n",
      "1    399300.SZ   20200102  4152.2408  4121.3487  4172.6555  4121.3487   \n",
      "2    399300.SZ   20191231  4096.5821  4077.7519  4098.1444  4069.0086   \n",
      "3    399300.SZ   20191230  4081.6334  4015.5195  4083.6901  4001.4951   \n",
      "4    399300.SZ   20191227  4022.0278  4029.2454  4066.7964  4019.7223   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "100  399300.SZ   20190807  3621.4310  3654.6323  3659.0778  3621.4310   \n",
      "101  399300.SZ   20190806  3636.3289  3609.1118  3649.8953  3575.8626   \n",
      "102  399300.SZ   20190805  3675.6884  3724.4097  3739.5031  3675.6884   \n",
      "103  399300.SZ   20190802  3747.4379  3729.1309  3754.5326  3720.0584   \n",
      "104  399300.SZ   20190801  3803.4694  3819.3242  3831.2641  3791.5460   \n",
      "\n",
      "     pre_close   change  pct_chg          vol       amount   dt  \\\n",
      "0    4152.2408  -7.2759  -0.1752  142826244.0  215216288.3    0   \n",
      "1    4096.5821  55.6587   1.3587  182116772.0  270105532.0    1   \n",
      "2    4081.6334  14.9487   0.3662  123264258.0  173119348.5    2   \n",
      "3    4022.0278  59.6056   1.4820  155971488.0  216814660.0    3   \n",
      "4    4025.9879  -3.9601  -0.0984  150926411.0  195090417.0    4   \n",
      "..         ...      ...      ...          ...          ...  ...   \n",
      "100  3636.3289 -14.8979  -0.4097   84238716.0  108667668.0  100   \n",
      "101  3675.6884 -39.3595  -1.0708  129833871.0  167267479.6  101   \n",
      "102  3747.4379 -71.7495  -1.9146  101325981.0  133061101.3  102   \n",
      "103  3803.4694 -56.0315  -1.4732  108335897.0  141874787.5  103   \n",
      "104  3835.3589 -31.8895  -0.8315   84114180.0  117649163.8  104   \n",
      "\n",
      "                             date  \n",
      "0   1970-01-01 00:00:00.000000000  \n",
      "1   1970-01-01 00:00:00.000000001  \n",
      "2   1970-01-01 00:00:00.000000002  \n",
      "3   1970-01-01 00:00:00.000000003  \n",
      "4   1970-01-01 00:00:00.000000004  \n",
      "..                            ...  \n",
      "100 1970-01-01 00:00:00.000000100  \n",
      "101 1970-01-01 00:00:00.000000101  \n",
      "102 1970-01-01 00:00:00.000000102  \n",
      "103 1970-01-01 00:00:00.000000103  \n",
      "104 1970-01-01 00:00:00.000000104  \n",
      "\n",
      "[105 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "baseline_df = plotter.get_baseline(\"399300.SZ\", ticket_type=TICKET_TYPE_INDEX)\n",
    "print(\"baseline_df \", baseline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============DRL Strategy Stats===========\n",
      "perf_stats_all: Annual return          0.412365\n",
      "Cumulative returns     0.153142\n",
      "Annual volatility      0.156216\n",
      "Sharpe ratio           2.310304\n",
      "Calmar ratio           7.048378\n",
      "Stability              0.639828\n",
      "Max drawdown          -0.058505\n",
      "Omega ratio            1.480388\n",
      "Sortino ratio          3.789312\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.079636\n",
      "Daily value at risk   -0.018249\n",
      "Alpha                       NaN\n",
      "Beta                        NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats \n",
    "perf_stats_all = perf_func(returns=daily_return, factor_returns=daily_return_base, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "print(\"==============DRL Strategy Stats===========\")\n",
    "print(f\"perf_stats_all: {perf_stats_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6J0LpdE7YuQe",
   "metadata": {
    "id": "6J0LpdE7YuQe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Baseline Strategy Stats===========\n",
      "perf_stats_all: Annual return         -0.186455\n",
      "Cumulative returns    -0.082388\n",
      "Annual volatility      0.132137\n",
      "Sharpe ratio          -1.510562\n",
      "Calmar ratio          -1.458535\n",
      "Stability              0.531397\n",
      "Max drawdown          -0.127837\n",
      "Omega ratio            0.786930\n",
      "Sortino ratio         -2.015469\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.055412\n",
      "Daily value at risk   -0.017440\n",
      "Alpha                  0.000000\n",
      "Beta                   1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats\n",
    "perf_stats_all = perf_func(returns=daily_return_base, factor_returns=daily_return_base, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "\n",
    "print(\"==============Baseline Strategy Stats===========\")\n",
    "\n",
    "print(f\"perf_stats_all: {perf_stats_all}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "China_A_share_market_tushare.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0492e5adbd22e67eab60cc68f6c8d46f59ec8e32b863d29391e70a96efcd66e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
