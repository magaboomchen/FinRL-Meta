{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "-G6H6HsRTFLn",
   "metadata": {
    "id": "-G6H6HsRTFLn"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Meta/blob/master/tutorials/1-Introduction/China_A_share_market_tushare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ShYRMdBTFLp",
   "metadata": {
    "id": "3ShYRMdBTFLp"
   },
   "source": [
    "## Quantitative trading in China A stock market with FinRL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pBU3DdPFTFLp",
   "metadata": {
    "id": "pBU3DdPFTFLp"
   },
   "source": [
    "Install FinRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51W37k2_TFLq",
   "metadata": {
    "id": "51W37k2_TFLq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ZmuaPTCTFLr",
   "metadata": {
    "id": "9ZmuaPTCTFLr"
   },
   "source": [
    "Install other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "q6T3o9yTTFLr",
   "metadata": {
    "id": "q6T3o9yTTFLr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install stockstats\n",
    "# !pip install tushare\n",
    "# #install talib\n",
    "# !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz \n",
    "# !tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "# import os\n",
    "# os.chdir('ta-lib') \n",
    "# !./configure --prefix=/usr\n",
    "# !make\n",
    "# !make install\n",
    "# #!sudo make install # Sometimes it need root \n",
    "# os.chdir('../')\n",
    "# !pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "DrReji1OTFLr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrReji1OTFLr",
    "outputId": "325c38e3-ca71-4b58-e0be-104e15011fe2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %cd /\n",
    "# !git clone https://github.com/AI4Finance-Foundation/FinRL-Meta\n",
    "# %cd /FinRL-Meta/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C-MYxgpJTMGP",
   "metadata": {
    "id": "C-MYxgpJTMGP"
   },
   "source": [
    "##Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Vx_hcZwgTKQp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vx_hcZwgTKQp",
    "outputId": "d6b36801-3064-4251-aadd-2396cb03ad5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL Modules have been imported!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd \n",
    "from IPython import display\n",
    "\n",
    "display.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "from meta import config \n",
    "from meta.data_processor import DataProcessor \n",
    "from main import check_and_make_directories \n",
    "from meta.data_processors.tushare import Tushare, ReturnPlotter \n",
    "from meta.data_processors.tushare_private import ReturnPlotterPrivate\n",
    "from meta.env_stock_trading.env_stocktrading_China_A_shares import StockTradingEnv \n",
    "from agents.stablebaselines3_models import DRLAgent \n",
    "import os \n",
    "from typing import List \n",
    "from argparse import ArgumentParser \n",
    "from meta import config \n",
    "from meta.config_tickers import DOW_30_TICKER \n",
    "from meta.config import ( DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR, INDICATORS, TRAIN_START_DATE, TRAIN_END_DATE, TEST_START_DATE, TEST_END_DATE, TRADE_START_DATE, TRADE_END_DATE, ERL_PARAMS, RLlib_PARAMS, SAC_PARAMS, ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL, )\n",
    "\n",
    "import pyfolio\n",
    "from pyfolio import timeseries\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "print(\"ALL Modules have been imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FRQz2ptSTjPJ",
   "metadata": {
    "id": "FRQz2ptSTjPJ"
   },
   "source": [
    "##Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pmttRZWWTXcd",
   "metadata": {
    "id": "pmttRZWWTXcd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' \n",
    "use check_and_make_directories() to replace the following\n",
    "\n",
    "if not os.path.exists(\"./datasets\"): \n",
    "  os.makedirs(\"./datasets\") \n",
    "if not os.path.exists(\"./trained_models\"): \n",
    "  os.makedirs(\"./trained_models\") \n",
    "if not os.path.exists(\"./tensorboard_log\"): \n",
    "  os.makedirs(\"./tensorboard_log\") \n",
    "if not os.path.exists(\"./results\"): \n",
    "  os.makedirs(\"./results\") \n",
    "'''\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94s2JtmxTuLq",
   "metadata": {
    "id": "94s2JtmxTuLq"
   },
   "source": [
    "##Download data, cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "xpPTz-xDTovy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpPTz-xDTovy",
    "outputId": "40df5f90-6211-452c-ee63-2dc2c849b370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tushare successfully connected\n"
     ]
    }
   ],
   "source": [
    "ticker_list = ['600000.SH', '600009.SH', '600016.SH', '600028.SH', '600030.SH', '600031.SH', '600036.SH', '600050.SH', '600104.SH', '600196.SH', '600276.SH', '600309.SH', '600519.SH', '600547.SH', '600570.SH']\n",
    "\n",
    "TRAIN_START_DATE = '2015-01-01' \n",
    "TRAIN_END_DATE= '2019-08-01' \n",
    "TRADE_START_DATE = '2019-08-01' \n",
    "TRADE_END_DATE = '2020-01-03'\n",
    "\n",
    "TIME_INTERVAL = \"1d\" \n",
    "kwargs = {} \n",
    "kwargs['token'] = '27080ec403c0218f96f388bca1b1d85329d563c91a43672239619ef5'\n",
    "p = DataProcessor(data_source='tushare', start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, time_interval=TIME_INTERVAL, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "svZh2OT0T7PG",
   "metadata": {
    "id": "svZh2OT0T7PG"
   },
   "source": [
    "###Download and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "v_PzruLIT3D1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_PzruLIT3D1",
    "outputId": "fa4b9030-f8ff-41a3-abef-77be4f9d37ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (17960, 8)\n",
      "Shape of DataFrame:  (18315, 8)\n"
     ]
    }
   ],
   "source": [
    "p.download_data(ticker_list=ticker_list)\n",
    "\n",
    "p.clean_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tsHu-XT_T_vQ",
   "metadata": {
    "id": "tsHu-XT_T_vQ"
   },
   "source": [
    "###Add technical indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "VfniyyQQT3nq",
   "metadata": {
    "id": "VfniyyQQT3nq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Shape of DataFrame:  (18270, 17)\n"
     ]
    }
   ],
   "source": [
    "p.add_technical_indicator(config.INDICATORS) \n",
    "p.clean_data()\n",
    "\n",
    "#print(f\"p.dataframe: {p.dataframe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cKZk3jGuUR34",
   "metadata": {
    "id": "cKZk3jGuUR34"
   },
   "source": [
    "##Split training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "SuKbrwflUVeU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuKbrwflUVeU",
    "outputId": "7596367b-670d-4d6c-b439-033075d87589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train.tic.unique()): 15\n"
     ]
    }
   ],
   "source": [
    "train = p.data_split(p.dataframe, TRAIN_START_DATE, TRAIN_END_DATE) \n",
    "\n",
    "print(f\"len(train.tic.unique()): {len(train.tic.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ONAnSMBUWyu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ONAnSMBUWyu",
    "outputId": "5bdf45d0-7689-4d31-dfa6-cbcbe8e64827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.tic.unique(): ['600000.SH' '600009.SH' '600016.SH' '600028.SH' '600030.SH' '600031.SH'\n",
      " '600036.SH' '600050.SH' '600104.SH' '600196.SH' '600276.SH' '600309.SH'\n",
      " '600519.SH' '600547.SH' '600570.SH']\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.tic.unique(): {train.tic.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "BXF8hYDvUXfv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXF8hYDvUXfv",
    "outputId": "a08ebe19-0107-4e31-c6df-816c846aa3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.head():          tic        date  index   open   high    low  close      volume  day  \\\n",
      "0  600000.SH  2015-01-08     45  15.87  15.88  15.20  15.25  3306271.72  3.0   \n",
      "0  600009.SH  2015-01-08     46  20.18  20.18  19.73  20.00   198117.45  3.0   \n",
      "0  600016.SH  2015-01-08     47  10.61  10.66  10.09  10.20  4851684.17  3.0   \n",
      "0  600028.SH  2015-01-08     48   7.09   7.41   6.83   6.85  8190902.35  3.0   \n",
      "0  600030.SH  2015-01-08     49  36.40  36.70  34.68  35.25  6376268.69  3.0   \n",
      "\n",
      "       macd    boll_ub    boll_lb     rsi_30      cci_30       dx_30  \\\n",
      "0 -0.032571  16.617911  15.012089   6.058641 -125.593009   23.014040   \n",
      "0 -0.016008  20.663897  19.736103  12.828915  -90.842491  100.000000   \n",
      "0 -0.018247  10.957604   9.997396  11.862558  -99.887006  100.000000   \n",
      "0 -0.008227   7.342000   6.743000  27.409248   36.578171   64.934862   \n",
      "0  0.032910  36.576444  33.808556  61.517448   47.947020  100.000000   \n",
      "\n",
      "   close_30_sma  close_60_sma  \n",
      "0       15.8150       15.8150  \n",
      "0       20.2000       20.2000  \n",
      "0       10.4775       10.4775  \n",
      "0        7.0425        7.0425  \n",
      "0       35.1925       35.1925  \n"
     ]
    }
   ],
   "source": [
    "print(f\"train.head(): {train.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "CnwNoBG5UXSQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnwNoBG5UXSQ",
    "outputId": "3bcf1c7a-e9de-4b92-fc7e-069904d9e6e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (16695, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.shape: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "joNhXi_ZUXId",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joNhXi_ZUXId",
    "outputId": "460b9763-6b0f-4976-f772-4a9a7cda2255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 15, State Space: 151\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique()) \n",
    "state_space = stock_dimension * (len(config.INDICATORS) + 2) + 1 \n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "le09273cUmzH",
   "metadata": {
    "id": "le09273cUmzH"
   },
   "source": [
    "##Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Npwpqkr7UpFF",
   "metadata": {
    "id": "Npwpqkr7UpFF"
   },
   "outputs": [],
   "source": [
    "env_kwargs = { \"stock_dim\": stock_dimension, \"hmax\": 1000, \"initial_amount\": 1000000, \"buy_cost_pct\": 6.87e-5, \"sell_cost_pct\": 1.0687e-3, \"reward_scaling\": 1e-4, \"state_space\": state_space, \"action_space\": stock_dimension, \"tech_indicator_list\": config.INDICATORS, \"print_verbosity\": 1, \"initial_buy\": True, \"hundred_each_trade\": True }\n",
    "\n",
    "e_train_gym = StockTradingEnv(df=train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1POZL3nUyDY",
   "metadata": {
    "id": "f1POZL3nUyDY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "print(type(env_train)): None\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env() \n",
    "\n",
    "print(f\"print(type(env_train)): {print(type(env_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QkY8sVWhU6PH",
   "metadata": {
    "id": "QkY8sVWhU6PH"
   },
   "source": [
    "###DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dLjEviBhUzuc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLjEviBhUzuc",
    "outputId": "58226aaa-41dc-45ce-9f5c-1e5cb94d27a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256, 'buffer_size': 50000, 'learning_rate': 0.0005, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1])}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_9\n",
      "Episode: 2\n",
      "day: 1112, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1949987.04\n",
      "total_reward: 949987.04\n",
      "total_cost: 11385.11\n",
      "total_trades: 16678\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "Episode: 3\n",
      "day: 1112, episode: 3\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1623245.01\n",
      "total_reward: 623245.01\n",
      "total_cost: 433.99\n",
      "total_trades: 16680\n",
      "Sharpe: 0.515\n",
      "=================================\n",
      "Episode: 4\n",
      "day: 1112, episode: 4\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1585873.01\n",
      "total_reward: 585873.01\n",
      "total_cost: 433.99\n",
      "total_trades: 16680\n",
      "Sharpe: 0.497\n",
      "=================================\n",
      "Episode: 5\n",
      "day: 1112, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1592124.03\n",
      "total_reward: 592124.03\n",
      "total_cost: 433.97\n",
      "total_trades: 16680\n",
      "Sharpe: 0.501\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 59         |\n",
      "|    time_elapsed    | 75         |\n",
      "|    total_timesteps | 4452       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -80.4      |\n",
      "|    critic_loss     | 652        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 3339       |\n",
      "|    reward          | -2.9364731 |\n",
      "-----------------------------------\n",
      "Episode: 6\n",
      "day: 1112, episode: 6\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1609342.02\n",
      "total_reward: 609342.02\n",
      "total_cost: 433.98\n",
      "total_trades: 16680\n",
      "Sharpe: 0.507\n",
      "=================================\n",
      "Episode: 7\n",
      "day: 1112, episode: 7\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1624562.02\n",
      "total_reward: 624562.02\n",
      "total_cost: 433.98\n",
      "total_trades: 16680\n",
      "Sharpe: 0.516\n",
      "=================================\n",
      "Episode: 8\n",
      "day: 1112, episode: 8\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1585187.01\n",
      "total_reward: 585187.01\n",
      "total_cost: 433.99\n",
      "total_trades: 16680\n",
      "Sharpe: 0.498\n",
      "=================================\n",
      "Episode: 9\n",
      "day: 1112, episode: 9\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1610028.01\n",
      "total_reward: 610028.01\n",
      "total_cost: 433.99\n",
      "total_trades: 16680\n",
      "Sharpe: 0.508\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 54         |\n",
      "|    time_elapsed    | 164        |\n",
      "|    total_timesteps | 8904       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -92.8      |\n",
      "|    critic_loss     | 199        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 7791       |\n",
      "|    reward          | -2.9673321 |\n",
      "-----------------------------------\n",
      "Episode: 10\n",
      "day: 1112, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1601303.04\n",
      "total_reward: 601303.04\n",
      "total_cost: 433.96\n",
      "total_trades: 16680\n",
      "Sharpe: 0.505\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env=env_train) \n",
    "DDPG_PARAMS = { \"batch_size\": 256, \"buffer_size\": 50000, \"learning_rate\": 0.0005, \"action_noise\": \"normal\", } \n",
    "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300])) \n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs=DDPG_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
    "\n",
    "trained_ddpg = agent.train_model(model=model_ddpg, tb_log_name='ddpg', total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ALJ1gqVmVEiU",
   "metadata": {
    "id": "ALJ1gqVmVEiU"
   },
   "source": [
    "###A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2F5qCGnNUzm7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2F5qCGnNUzm7",
    "outputId": "b8db239f-7d37-4587-c511-0f2dc4c6f273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_7\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 146         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.3       |\n",
      "|    explained_variance | -0.0032     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -32.4       |\n",
      "|    reward             | -0.24292411 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 4.11        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -21.3    |\n",
      "|    explained_variance | 0.413    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 39.9     |\n",
      "|    reward             | 2.230589 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.74     |\n",
      "------------------------------------\n",
      "Episode: 12\n",
      "day: 1112, episode: 12\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1039475.82\n",
      "total_reward: 39475.82\n",
      "total_cost: 87812.33\n",
      "total_trades: 16662\n",
      "Sharpe: 0.167\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 142         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.3       |\n",
      "|    explained_variance | 0.0877      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -15.6       |\n",
      "|    reward             | -0.03008703 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.764       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 160        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -20.8      |\n",
      "|    reward             | -0.6481513 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.33       |\n",
      "--------------------------------------\n",
      "Episode: 13\n",
      "day: 1112, episode: 13\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 564111.23\n",
      "total_reward: -435888.77\n",
      "total_cost: 29131.77\n",
      "total_trades: 16664\n",
      "Sharpe: 0.012\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 174        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.4      |\n",
      "|    explained_variance | 0.107      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 28.4       |\n",
      "|    reward             | -3.6916714 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.71       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 183        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -81.8      |\n",
      "|    reward             | -2.5281587 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 19.6       |\n",
      "--------------------------------------\n",
      "Episode: 14\n",
      "day: 1112, episode: 14\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 944746.29\n",
      "total_reward: -55253.71\n",
      "total_cost: 41736.71\n",
      "total_trades: 16670\n",
      "Sharpe: 0.120\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 187         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 0.0185      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -265        |\n",
      "|    reward             | -0.58703196 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 212         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 192         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -118        |\n",
      "|    reward             | -0.66439444 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 31.7        |\n",
      "---------------------------------------\n",
      "Episode: 15\n",
      "day: 1112, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 971319.08\n",
      "total_reward: -28680.92\n",
      "total_cost: 18501.92\n",
      "total_trades: 16676\n",
      "Sharpe: 0.162\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 9.39        |\n",
      "|    reward             | -0.46949914 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.7      |\n",
      "|    explained_variance | -2.14      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 78.5       |\n",
      "|    reward             | 0.19866386 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 204        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.7      |\n",
      "|    explained_variance | -0.125     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -27.9      |\n",
      "|    reward             | -2.7831008 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 6.22       |\n",
      "--------------------------------------\n",
      "Episode: 16\n",
      "day: 1112, episode: 16\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1060077.81\n",
      "total_reward: 60077.81\n",
      "total_cost: 59178.19\n",
      "total_trades: 16670\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.7       |\n",
      "|    explained_variance | -0.0774     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -70.7       |\n",
      "|    reward             | 0.043245856 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 11.1        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.7       |\n",
      "|    explained_variance | 0.0882      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -17.5       |\n",
      "|    reward             | -0.21079993 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 3.36        |\n",
      "---------------------------------------\n",
      "Episode: 17\n",
      "day: 1112, episode: 17\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1146952.31\n",
      "total_reward: 146952.31\n",
      "total_cost: 58727.69\n",
      "total_trades: 16668\n",
      "Sharpe: 0.252\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 191        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 36         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.7      |\n",
      "|    explained_variance | 0.0968     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 5.16       |\n",
      "|    reward             | -0.9203565 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 187        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.7      |\n",
      "|    explained_variance | -0.0835    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -34.9      |\n",
      "|    reward             | -1.6963749 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 4.17       |\n",
      "--------------------------------------\n",
      "Episode: 18\n",
      "day: 1112, episode: 18\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1338511.36\n",
      "total_reward: 338511.36\n",
      "total_cost: 50186.64\n",
      "total_trades: 16672\n",
      "Sharpe: 0.375\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 189        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.8      |\n",
      "|    explained_variance | -0.0517    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -12.1      |\n",
      "|    reward             | -0.0305189 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 1.94       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 191       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.8     |\n",
      "|    explained_variance | -0.741    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -17.2     |\n",
      "|    reward             | 0.3265799 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 5.35      |\n",
      "-------------------------------------\n",
      "Episode: 19\n",
      "day: 1112, episode: 19\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1940586.01\n",
      "total_reward: 940586.01\n",
      "total_cost: 39530.99\n",
      "total_trades: 16670\n",
      "Sharpe: 0.748\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 191         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | 0.397       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 45.1        |\n",
      "|    reward             | -0.28702608 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 10          |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 192       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.8     |\n",
      "|    explained_variance | -4.27     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -64.7     |\n",
      "|    reward             | 1.0189722 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 10.7      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 193         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | 0.264       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 31.1        |\n",
      "|    reward             | -0.49985486 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 2.38        |\n",
      "---------------------------------------\n",
      "Episode: 20\n",
      "day: 1112, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1222708.24\n",
      "total_reward: 222708.24\n",
      "total_cost: 53991.76\n",
      "total_trades: 16679\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 53          |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | -3.09       |\n",
      "|    reward             | -0.04066433 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.0264      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 195         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | 4.73        |\n",
      "|    reward             | -0.07511176 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.08        |\n",
      "---------------------------------------\n",
      "Episode: 21\n",
      "day: 1112, episode: 21\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1076158.34\n",
      "total_reward: 76158.34\n",
      "total_cost: 52887.66\n",
      "total_trades: 16673\n",
      "Sharpe: 0.212\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 197        |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 58         |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | 40.9       |\n",
      "|    reward             | -0.3245126 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 5.04       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 198        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | 0.568      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | 1.08       |\n",
      "|    reward             | -0.4355326 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.782      |\n",
      "--------------------------------------\n",
      "Episode: 22\n",
      "day: 1112, episode: 22\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1221892.40\n",
      "total_reward: 221892.40\n",
      "total_cost: 55588.60\n",
      "total_trades: 16675\n",
      "Sharpe: 0.309\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 198        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 62         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | -0.00338   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | -33.9      |\n",
      "|    reward             | -2.3367414 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 4.44       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | 0.184      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | -8.76      |\n",
      "|    reward             | -4.8943844 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 6.22       |\n",
      "--------------------------------------\n",
      "Episode: 23\n",
      "day: 1112, episode: 23\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1930634.40\n",
      "total_reward: 930634.40\n",
      "total_cost: 48291.60\n",
      "total_trades: 16671\n",
      "Sharpe: 0.625\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.1     |\n",
      "|    explained_variance | 0.0983    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 87.2      |\n",
      "|    reward             | 3.7987528 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 17.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.1     |\n",
      "|    explained_variance | -1.05     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 29.1      |\n",
      "|    reward             | 1.7589213 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.89      |\n",
      "-------------------------------------\n",
      "Episode: 24\n",
      "day: 1112, episode: 24\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1254985.02\n",
      "total_reward: 254985.02\n",
      "total_cost: 28505.98\n",
      "total_trades: 16674\n",
      "Sharpe: 0.322\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | 5.68        |\n",
      "|    reward             | -0.03243594 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.106       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2999         |\n",
      "|    policy_loss        | 4.47         |\n",
      "|    reward             | -0.052269932 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.0627       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | -4.86       |\n",
      "|    reward             | -0.12592292 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.0624      |\n",
      "---------------------------------------\n",
      "Episode: 25\n",
      "day: 1112, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 952024.86\n",
      "total_reward: -47975.14\n",
      "total_cost: 24668.14\n",
      "total_trades: 16676\n",
      "Sharpe: -0.084\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 207       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.4     |\n",
      "|    explained_variance | -0.237    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -34.3     |\n",
      "|    reward             | 1.1954393 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 3.15      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | -81.6        |\n",
      "|    reward             | 0.0057249027 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 21.4         |\n",
      "----------------------------------------\n",
      "Episode: 26\n",
      "day: 1112, episode: 26\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1287363.50\n",
      "total_reward: 287363.50\n",
      "total_cost: 28062.50\n",
      "total_trades: 16676\n",
      "Sharpe: 0.392\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 209        |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | 8.13       |\n",
      "|    reward             | 0.35146698 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.154      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 210       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -16.5     |\n",
      "|    reward             | 0.5475824 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 2.44      |\n",
      "-------------------------------------\n",
      "Episode: 27\n",
      "day: 1112, episode: 27\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 736073.78\n",
      "total_reward: -263926.22\n",
      "total_cost: 29277.22\n",
      "total_trades: 16675\n",
      "Sharpe: -0.301\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 212        |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 84         |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.5      |\n",
      "|    explained_variance | -2.35      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | -6.39      |\n",
      "|    reward             | 0.19652727 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.35       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 212        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.5      |\n",
      "|    explained_variance | 0.507      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | 8.17       |\n",
      "|    reward             | -0.3566489 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.305      |\n",
      "--------------------------------------\n",
      "Episode: 28\n",
      "day: 1112, episode: 28\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 709381.27\n",
      "total_reward: -290618.73\n",
      "total_cost: 26394.73\n",
      "total_trades: 16670\n",
      "Sharpe: -0.357\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 213         |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | -0.572      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -18.1       |\n",
      "|    reward             | -0.48970595 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.958       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 214       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.5     |\n",
      "|    explained_variance | 0.509     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -46.9     |\n",
      "|    reward             | 2.4154592 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 3.74      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 214         |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | 9.66        |\n",
      "|    reward             | 0.023098273 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "Episode: 29\n",
      "day: 1112, episode: 29\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 647348.25\n",
      "total_reward: -352651.75\n",
      "total_cost: 16643.75\n",
      "total_trades: 16672\n",
      "Sharpe: -0.357\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 215          |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | 20.7         |\n",
      "|    reward             | -0.008821268 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 1.08         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 214         |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | 2.97        |\n",
      "|    reward             | -0.13192241 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.0344      |\n",
      "---------------------------------------\n",
      "Episode: 30\n",
      "day: 1112, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 961135.57\n",
      "total_reward: -38864.43\n",
      "total_cost: 13676.43\n",
      "total_trades: 16675\n",
      "Sharpe: -0.015\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 211          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | -1.87        |\n",
      "|    reward             | -0.043689337 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.0113       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 210        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 104        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | -4.2       |\n",
      "|    reward             | 0.14642443 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.0594     |\n",
      "--------------------------------------\n",
      "Episode: 31\n",
      "day: 1112, episode: 31\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 983258.10\n",
      "total_reward: -16741.90\n",
      "total_cost: 13916.90\n",
      "total_trades: 16676\n",
      "Sharpe: -0.106\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 210         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | -1.69       |\n",
      "|    reward             | -0.06513895 |\n",
      "|    std                | 1.13        |\n",
      "|    value_loss         | 0.00844     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 210         |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | 9.09        |\n",
      "|    reward             | -0.19932845 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "Episode: 32\n",
      "day: 1112, episode: 32\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 948338.93\n",
      "total_reward: -51661.07\n",
      "total_cost: 22221.07\n",
      "total_trades: 16676\n",
      "Sharpe: -0.296\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 208         |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | 8.87        |\n",
      "|    reward             | 0.071781695 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 207        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | -5.53      |\n",
      "|    reward             | -0.2643191 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.0592     |\n",
      "--------------------------------------\n",
      "Episode: 33\n",
      "day: 1112, episode: 33\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1093623.32\n",
      "total_reward: 93623.32\n",
      "total_cost: 33653.68\n",
      "total_trades: 16677\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | -3           |\n",
      "|    reward             | -0.044396386 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 0.204        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 207       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.6     |\n",
      "|    explained_variance | -0.101    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -28.9     |\n",
      "|    reward             | 1.8994552 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 1.74      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 207        |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 122        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.7      |\n",
      "|    explained_variance | -0.248     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | 0.534      |\n",
      "|    reward             | -2.2564719 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 2.62       |\n",
      "--------------------------------------\n",
      "Episode: 34\n",
      "day: 1112, episode: 34\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998345.80\n",
      "total_reward: -1654.20\n",
      "total_cost: 30792.20\n",
      "total_trades: 16675\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 204      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -23.7    |\n",
      "|    explained_variance | -0.591   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 4.1      |\n",
      "|    reward             | -2.35644 |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 202      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -23.7    |\n",
      "|    explained_variance | 0.138    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -37.2    |\n",
      "|    reward             | 2.150971 |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 4.64     |\n",
      "------------------------------------\n",
      "Episode: 35\n",
      "day: 1112, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1067101.26\n",
      "total_reward: 67101.26\n",
      "total_cost: 33872.74\n",
      "total_trades: 16675\n",
      "Sharpe: 0.205\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 135       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.7     |\n",
      "|    explained_variance | -0.205    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 74.4      |\n",
      "|    reward             | 2.4443152 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 12        |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 199         |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | -0.00761    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5499        |\n",
      "|    policy_loss        | -174        |\n",
      "|    reward             | -0.09145869 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 63.4        |\n",
      "---------------------------------------\n",
      "Episode: 36\n",
      "day: 1112, episode: 36\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 990651.73\n",
      "total_reward: -9348.27\n",
      "total_cost: 43251.27\n",
      "total_trades: 16674\n",
      "Sharpe: 0.144\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 199         |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0.508       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -21.2       |\n",
      "|    reward             | -0.73510796 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 200         |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0.245       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | 41.1        |\n",
      "|    reward             | -0.24242081 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 7.33        |\n",
      "---------------------------------------\n",
      "Episode: 37\n",
      "day: 1112, episode: 37\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1217138.34\n",
      "total_reward: 217138.34\n",
      "total_cost: 51014.66\n",
      "total_trades: 16674\n",
      "Sharpe: 0.301\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 200         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | -0.335      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 10          |\n",
      "|    reward             | 0.031434365 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 147        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.8      |\n",
      "|    explained_variance | -0.246     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | 2.74       |\n",
      "|    reward             | -0.5583962 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 5.8        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 149        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.8      |\n",
      "|    explained_variance | 0.0912     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | -62.8      |\n",
      "|    reward             | 0.44596255 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 10.1       |\n",
      "--------------------------------------\n",
      "Episode: 38\n",
      "day: 1112, episode: 38\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1179169.20\n",
      "total_reward: 179169.20\n",
      "total_cost: 48950.80\n",
      "total_trades: 16675\n",
      "Sharpe: 0.278\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.8     |\n",
      "|    explained_variance | -0.0416   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -2.14     |\n",
      "|    reward             | 0.0473745 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.204     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.8     |\n",
      "|    explained_variance | -0.112    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -68.1     |\n",
      "|    reward             | 1.0993356 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 11        |\n",
      "-------------------------------------\n",
      "Episode: 39\n",
      "day: 1112, episode: 39\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1297144.25\n",
      "total_reward: 297144.25\n",
      "total_cost: 61028.75\n",
      "total_trades: 16666\n",
      "Sharpe: 0.353\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0.0475      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | -19.7       |\n",
      "|    reward             | -0.07731359 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.937       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 202        |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.8      |\n",
      "|    explained_variance | 0.0644     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | 78.5       |\n",
      "|    reward             | -3.2200012 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 20.3       |\n",
      "--------------------------------------\n",
      "Episode: 40\n",
      "day: 1112, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1172556.66\n",
      "total_reward: 172556.66\n",
      "total_cost: 56528.34\n",
      "total_trades: 16670\n",
      "Sharpe: 0.270\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 6500        |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 32500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | -0.987      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6499        |\n",
      "|    policy_loss        | -39.9       |\n",
      "|    reward             | -0.40302297 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 7.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0.133       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -11         |\n",
      "|    reward             | -0.30057433 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "Episode: 41\n",
      "day: 1112, episode: 41\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 557616.30\n",
      "total_reward: -442383.70\n",
      "total_cost: 56425.70\n",
      "total_trades: 16674\n",
      "Sharpe: -0.095\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 203       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.9     |\n",
      "|    explained_variance | -0.388    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -121      |\n",
      "|    reward             | 1.5284351 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 26.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 203      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -23.9    |\n",
      "|    explained_variance | 0.124    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 5.83     |\n",
      "|    reward             | 1.753278 |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.344    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 203        |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 169        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | 0.0287     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -46.1      |\n",
      "|    reward             | -0.9173583 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 5.65       |\n",
      "--------------------------------------\n",
      "Episode: 42\n",
      "day: 1112, episode: 42\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1020828.89\n",
      "total_reward: 20828.89\n",
      "total_cost: 55656.11\n",
      "total_trades: 16675\n",
      "Sharpe: 0.182\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 203        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 171        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.8      |\n",
      "|    explained_variance | -0.7       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 9.68       |\n",
      "|    reward             | 0.38692945 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 0.246      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 203       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.8     |\n",
      "|    explained_variance | 0.0643    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 10        |\n",
      "|    reward             | 3.4621468 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 1.8       |\n",
      "-------------------------------------\n",
      "Episode: 43\n",
      "day: 1112, episode: 43\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1042717.58\n",
      "total_reward: 42717.58\n",
      "total_cost: 45302.42\n",
      "total_trades: 16675\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 204        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 176        |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | -0.219     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | 102        |\n",
      "|    reward             | -0.5700005 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 22.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 204       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.8     |\n",
      "|    explained_variance | 0.0481    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 8.97      |\n",
      "|    reward             | 1.7358992 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 2.54      |\n",
      "-------------------------------------\n",
      "Episode: 44\n",
      "day: 1112, episode: 44\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1107199.02\n",
      "total_reward: 107199.02\n",
      "total_cost: 48490.98\n",
      "total_trades: 16678\n",
      "Sharpe: 0.228\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 204       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.9     |\n",
      "|    explained_variance | -0.142    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -13.4     |\n",
      "|    reward             | 1.0840638 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.859     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.9       |\n",
      "|    explained_variance | -0.144      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | -11.4       |\n",
      "|    reward             | 0.078983806 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "Episode: 45\n",
      "day: 1112, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1080168.06\n",
      "total_reward: 80168.06\n",
      "total_cost: 52426.94\n",
      "total_trades: 16674\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 205       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.9     |\n",
      "|    explained_variance | 0.00302   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -162      |\n",
      "|    reward             | 1.6105287 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 63.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 206        |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 186        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | 0.127      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -15        |\n",
      "|    reward             | -0.8310857 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 0.683      |\n",
      "--------------------------------------\n",
      "Episode: 46\n",
      "day: 1112, episode: 46\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1018583.51\n",
      "total_reward: 18583.51\n",
      "total_cost: 44701.49\n",
      "total_trades: 16675\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 206        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | -0.00815   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | 80.4       |\n",
      "|    reward             | -1.3329823 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 13         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 206       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.9     |\n",
      "|    explained_variance | -0.265    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -12       |\n",
      "|    reward             | 1.1625171 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 1.46      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.9       |\n",
      "|    explained_variance | -0.00352    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | -7.71       |\n",
      "|    reward             | 0.043578587 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 2.77        |\n",
      "---------------------------------------\n",
      "Episode: 47\n",
      "day: 1112, episode: 47\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 993416.06\n",
      "total_reward: -6583.94\n",
      "total_cost: 33147.94\n",
      "total_trades: 16677\n",
      "Sharpe: 0.157\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 206       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 195       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.9     |\n",
      "|    explained_variance | -0.22     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -4.19     |\n",
      "|    reward             | 1.1652298 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 1.51      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 207        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 197        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | -0.0688    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -147       |\n",
      "|    reward             | -1.4523153 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 45.6       |\n",
      "--------------------------------------\n",
      "Episode: 48\n",
      "day: 1112, episode: 48\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 983587.12\n",
      "total_reward: -16412.88\n",
      "total_cost: 44174.88\n",
      "total_trades: 16674\n",
      "Sharpe: 0.143\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 207       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.9     |\n",
      "|    explained_variance | -1.65     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -8.54     |\n",
      "|    reward             | 0.7135145 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 0.401     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 208        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 201        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | -0.194     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | 4.56       |\n",
      "|    reward             | 0.08251127 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 1.6        |\n",
      "--------------------------------------\n",
      "Episode: 49\n",
      "day: 1112, episode: 49\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1114293.26\n",
      "total_reward: 114293.26\n",
      "total_cost: 53669.74\n",
      "total_trades: 16678\n",
      "Sharpe: 0.235\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 208        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 203        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | -0.454     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | 98.2       |\n",
      "|    reward             | -1.5936242 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 19.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 208        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 205        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | -0.0964    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | -2.39      |\n",
      "|    reward             | -1.1758419 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 1.99       |\n",
      "--------------------------------------\n",
      "Episode: 50\n",
      "day: 1112, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1358751.30\n",
      "total_reward: 358751.30\n",
      "total_cost: 61190.70\n",
      "total_trades: 16671\n",
      "Sharpe: 0.375\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 209       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -24       |\n",
      "|    explained_variance | -0.106    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 11.8      |\n",
      "|    reward             | -8.726086 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 1.94      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 209        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | 0.259      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | 27         |\n",
      "|    reward             | -2.5839288 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 3.14       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 208        |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 213        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | 0.0292     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | 24.6       |\n",
      "|    reward             | -3.0461414 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 28.8       |\n",
      "--------------------------------------\n",
      "Episode: 51\n",
      "day: 1112, episode: 51\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1506629.10\n",
      "total_reward: 506629.10\n",
      "total_cost: 68148.90\n",
      "total_trades: 16652\n",
      "Sharpe: 0.439\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 206        |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | -0.131     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | -33.2      |\n",
      "|    reward             | -0.6604391 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 4.88       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 205       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 221       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -24       |\n",
      "|    explained_variance | -0.112    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 55        |\n",
      "|    reward             | -0.693065 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 7.35      |\n",
      "-------------------------------------\n",
      "Episode: 52\n",
      "day: 1112, episode: 52\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1413138.35\n",
      "total_reward: 413138.35\n",
      "total_cost: 57930.65\n",
      "total_trades: 16672\n",
      "Sharpe: 0.406\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 205       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 223       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -24       |\n",
      "|    explained_variance | 0.0339    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 240       |\n",
      "|    reward             | 7.2078266 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 108       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 205        |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 225        |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | -0.189     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | 7.91       |\n",
      "|    reward             | -1.5542412 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 1.32       |\n",
      "--------------------------------------\n",
      "Episode: 53\n",
      "day: 1112, episode: 53\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1350191.29\n",
      "total_reward: 350191.29\n",
      "total_cost: 63007.71\n",
      "total_trades: 16678\n",
      "Sharpe: 0.369\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 206        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 228        |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | -0.00227   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | -126       |\n",
      "|    reward             | -1.4065007 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 41         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 205       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 230       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.9     |\n",
      "|    explained_variance | 0.00769   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -127      |\n",
      "|    reward             | 0.9369864 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 28.3      |\n",
      "-------------------------------------\n",
      "Episode: 54\n",
      "day: 1112, episode: 54\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1387691.84\n",
      "total_reward: 387691.84\n",
      "total_cost: 73512.16\n",
      "total_trades: 16663\n",
      "Sharpe: 0.390\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 206        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 232        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | 0.051      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | -34        |\n",
      "|    reward             | -1.5066881 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 13.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 206        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 234        |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | -0.271     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | -31.9      |\n",
      "|    reward             | -2.1535873 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 2.67       |\n",
      "--------------------------------------\n",
      "Episode: 55\n",
      "day: 1112, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1104400.53\n",
      "total_reward: 104400.53\n",
      "total_cost: 74479.47\n",
      "total_trades: 16670\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | 0.122       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | -26         |\n",
      "|    reward             | 0.115723625 |\n",
      "|    std                | 1.2         |\n",
      "|    value_loss         | 4.55        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24          |\n",
      "|    explained_variance | -0.189       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -91.1        |\n",
      "|    reward             | -0.079881705 |\n",
      "|    std                | 1.2          |\n",
      "|    value_loss         | 15.7         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 207        |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 241        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | -0.299     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 82.5       |\n",
      "|    reward             | -2.2596896 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 12.6       |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env=env_train) \n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c', total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ArAnGULyVVfK",
   "metadata": {
    "id": "ArAnGULyVVfK"
   },
   "source": [
    "##Trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "TzU6JBAWVGPG",
   "metadata": {
    "id": "TzU6JBAWVGPG"
   },
   "outputs": [],
   "source": [
    "trade = p.data_split(p.dataframe, TRADE_START_DATE, TRADE_END_DATE) \n",
    "env_kwargs = { \"stock_dim\": stock_dimension, \"hmax\": 1000, \"initial_amount\": 1000000, \"buy_cost_pct\": 6.87e-5, \"sell_cost_pct\": 1.0687e-3, \"reward_scaling\": 1e-4, \"state_space\": state_space, \"action_space\": stock_dimension, \"tech_indicator_list\": config.INDICATORS, \"print_verbosity\": 1, \"initial_buy\": False, \"hundred_each_trade\": True } \n",
    "e_trade_gym = StockTradingEnv(df=trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdg8qypiVSOn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdg8qypiVSOn",
    "outputId": "af6f6967-7e06-41c5-850f-d0e2512ecd43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\n",
      "day: 103, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1153142.32\n",
      "total_reward: 153142.32\n",
      "total_cost: 68.68\n",
      "total_trades: 618\n",
      "Sharpe: 2.310\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ddpg, environment=e_trade_gym)\n",
    "# import pickle\n",
    "# with open('./df_account_value.pickle', 'wb') as handle:\n",
    "#     pickle.dump(df_account_value, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86d82263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  account_value\n",
      "0    2019-08-01   1.000000e+06\n",
      "1    2019-08-02   9.972021e+05\n",
      "2    2019-08-05   9.826644e+05\n",
      "3    2019-08-06   9.825871e+05\n",
      "4    2019-08-07   9.830335e+05\n",
      "..          ...            ...\n",
      "99   2019-12-26   1.120953e+06\n",
      "100  2019-12-27   1.125883e+06\n",
      "101  2019-12-30   1.139063e+06\n",
      "102  2019-12-31   1.151556e+06\n",
      "103  2020-01-02   1.153142e+06\n",
      "\n",
      "[104 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_account_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "Ih4rdH3uVSo1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ih4rdH3uVSo1",
    "outputId": "291d8234-ee54-4ef2-a511-1e084a783f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_actions:             600000.SH  600009.SH  600016.SH  600028.SH  600030.SH  600031.SH  \\\n",
      "date                                                                           \n",
      "2019-08-01          0       1000       1000          0          0          0   \n",
      "2019-08-02          0       1000       1000          0          0          0   \n",
      "2019-08-05          0       1000       1000          0          0          0   \n",
      "2019-08-06          0        700       1000          0          0          0   \n",
      "2019-08-07          0          0        100          0          0          0   \n",
      "...               ...        ...        ...        ...        ...        ...   \n",
      "2019-12-25          0          0          0          0          0          0   \n",
      "2019-12-26          0          0          0          0          0          0   \n",
      "2019-12-27          0          0          0          0          0          0   \n",
      "2019-12-30          0          0          0          0          0          0   \n",
      "2019-12-31          0          0          0          0          0          0   \n",
      "\n",
      "            600036.SH  600050.SH  600104.SH  600196.SH  600276.SH  600309.SH  \\\n",
      "date                                                                           \n",
      "2019-08-01       1000          0          0       1000       1000       1000   \n",
      "2019-08-02       1000          0          0       1000       1000       1000   \n",
      "2019-08-05       1000          0          0       1000       1000       1000   \n",
      "2019-08-06       1000          0          0       1000       1000       1000   \n",
      "2019-08-07          0          0          0        100          0          0   \n",
      "...               ...        ...        ...        ...        ...        ...   \n",
      "2019-12-25          0          0          0          0          0          0   \n",
      "2019-12-26          0          0          0          0          0          0   \n",
      "2019-12-27          0          0          0          0          0          0   \n",
      "2019-12-30          0          0          0          0          0          0   \n",
      "2019-12-31          0          0          0          0          0          0   \n",
      "\n",
      "            600519.SH  600547.SH  600570.SH  \n",
      "date                                         \n",
      "2019-08-01          0          0          0  \n",
      "2019-08-02          0          0          0  \n",
      "2019-08-05          0          0          0  \n",
      "2019-08-06          0          0          0  \n",
      "2019-08-07          0          0          0  \n",
      "...               ...        ...        ...  \n",
      "2019-12-25          0          0          0  \n",
      "2019-12-26          0          0          0  \n",
      "2019-12-27          0          0          0  \n",
      "2019-12-30          0          0          0  \n",
      "2019-12-31          0          0          0  \n",
      "\n",
      "[103 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "df_actions.to_csv(\"action.csv\", index=False) \n",
    "print(f\"df_actions: {df_actions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l7X1KIaVWUYp",
   "metadata": {
    "id": "l7X1KIaVWUYp"
   },
   "source": [
    "##Backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dUJn8einWPKI",
   "metadata": {
    "id": "dUJn8einWPKI"
   },
   "source": [
    "###matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pR6hNouKWOoY",
   "metadata": {
    "id": "pR6hNouKWOoY"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import meta.data_processors.tushare_private\n",
    "importlib.reload(meta.data_processors.tushare_private)\n",
    "from meta.data_processors.tushare_private import ReturnPlotterPrivate, TICKET_TYPE_INDEX, TICKET_TYPE_TICKET\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plotter = ReturnPlotterPrivate(df_account_value, trade, TRADE_START_DATE, TRADE_END_DATE)\n",
    "plotter.plot(figure_filepath=\"./China_A_share.png\")\n",
    "# plotter.plot()\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "Qx62Q575YC9I",
   "metadata": {
    "id": "Qx62Q575YC9I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TICKET_TYPE_INDEX\n"
     ]
    }
   ],
   "source": [
    "# ticket: SSE 50：000016.SH\n",
    "baseline_ticket = \"000016.SH\"\n",
    "plotter.plot(baseline_ticket, figure_filepath=\"./China_A_share_vs_{0}.png\".format(baseline_ticket), ticket_type=TICKET_TYPE_INDEX)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XUAh2S9Lamxe",
   "metadata": {
    "id": "XUAh2S9Lamxe"
   },
   "source": [
    "###CSI 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ZSRJpKINYcBa",
   "metadata": {
    "id": "ZSRJpKINYcBa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TICKET_TYPE_INDEX\n",
      "baseline_df         ts_code trade_date      close       open       high        low  \\\n",
      "0    399300.SZ   20200103  4144.9649  4161.2185  4164.2989  4131.8640   \n",
      "1    399300.SZ   20200102  4152.2408  4121.3487  4172.6555  4121.3487   \n",
      "2    399300.SZ   20191231  4096.5821  4077.7519  4098.1444  4069.0086   \n",
      "3    399300.SZ   20191230  4081.6334  4015.5195  4083.6901  4001.4951   \n",
      "4    399300.SZ   20191227  4022.0278  4029.2454  4066.7964  4019.7223   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "100  399300.SZ   20190807  3621.4310  3654.6323  3659.0778  3621.4310   \n",
      "101  399300.SZ   20190806  3636.3289  3609.1118  3649.8953  3575.8626   \n",
      "102  399300.SZ   20190805  3675.6884  3724.4097  3739.5031  3675.6884   \n",
      "103  399300.SZ   20190802  3747.4379  3729.1309  3754.5326  3720.0584   \n",
      "104  399300.SZ   20190801  3803.4694  3819.3242  3831.2641  3791.5460   \n",
      "\n",
      "     pre_close   change  pct_chg          vol       amount   dt  \\\n",
      "0    4152.2408  -7.2759  -0.1752  142826244.0  215216288.3    0   \n",
      "1    4096.5821  55.6587   1.3587  182116772.0  270105532.0    1   \n",
      "2    4081.6334  14.9487   0.3662  123264258.0  173119348.5    2   \n",
      "3    4022.0278  59.6056   1.4820  155971488.0  216814660.0    3   \n",
      "4    4025.9879  -3.9601  -0.0984  150926411.0  195090417.0    4   \n",
      "..         ...      ...      ...          ...          ...  ...   \n",
      "100  3636.3289 -14.8979  -0.4097   84238716.0  108667668.0  100   \n",
      "101  3675.6884 -39.3595  -1.0708  129833871.0  167267479.6  101   \n",
      "102  3747.4379 -71.7495  -1.9146  101325981.0  133061101.3  102   \n",
      "103  3803.4694 -56.0315  -1.4732  108335897.0  141874787.5  103   \n",
      "104  3835.3589 -31.8895  -0.8315   84114180.0  117649163.8  104   \n",
      "\n",
      "                             date  \n",
      "0   1970-01-01 00:00:00.000000000  \n",
      "1   1970-01-01 00:00:00.000000001  \n",
      "2   1970-01-01 00:00:00.000000002  \n",
      "3   1970-01-01 00:00:00.000000003  \n",
      "4   1970-01-01 00:00:00.000000004  \n",
      "..                            ...  \n",
      "100 1970-01-01 00:00:00.000000100  \n",
      "101 1970-01-01 00:00:00.000000101  \n",
      "102 1970-01-01 00:00:00.000000102  \n",
      "103 1970-01-01 00:00:00.000000103  \n",
      "104 1970-01-01 00:00:00.000000104  \n",
      "\n",
      "[105 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "baseline_df = plotter.get_baseline(\"399300.SZ\", ticket_type=TICKET_TYPE_INDEX)\n",
    "print(\"baseline_df \", baseline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e47f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============DRL Strategy Stats===========\n",
      "perf_stats_all: Annual return          0.412365\n",
      "Cumulative returns     0.153142\n",
      "Annual volatility      0.156216\n",
      "Sharpe ratio           2.310304\n",
      "Calmar ratio           7.048378\n",
      "Stability              0.639828\n",
      "Max drawdown          -0.058505\n",
      "Omega ratio            1.480388\n",
      "Sortino ratio          3.789312\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.079636\n",
      "Daily value at risk   -0.018249\n",
      "Alpha                       NaN\n",
      "Beta                        NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats \n",
    "perf_stats_all = perf_func(returns=daily_return, factor_returns=daily_return_base, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "print(\"==============DRL Strategy Stats===========\")\n",
    "print(f\"perf_stats_all: {perf_stats_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6J0LpdE7YuQe",
   "metadata": {
    "id": "6J0LpdE7YuQe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Baseline Strategy Stats===========\n",
      "perf_stats_all: Annual return         -0.186455\n",
      "Cumulative returns    -0.082388\n",
      "Annual volatility      0.132137\n",
      "Sharpe ratio          -1.510562\n",
      "Calmar ratio          -1.458535\n",
      "Stability              0.531397\n",
      "Max drawdown          -0.127837\n",
      "Omega ratio            0.786930\n",
      "Sortino ratio         -2.015469\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.055412\n",
      "Daily value at risk   -0.017440\n",
      "Alpha                  0.000000\n",
      "Beta                   1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats\n",
    "perf_stats_all = perf_func(returns=daily_return_base, factor_returns=daily_return_base, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "\n",
    "print(\"==============Baseline Strategy Stats===========\")\n",
    "\n",
    "print(f\"perf_stats_all: {perf_stats_all}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "China_A_share_market_tushare.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0492e5adbd22e67eab60cc68f6c8d46f59ec8e32b863d29391e70a96efcd66e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
