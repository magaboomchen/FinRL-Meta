{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "-G6H6HsRTFLn",
   "metadata": {
    "id": "-G6H6HsRTFLn"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Meta/blob/master/tutorials/1-Introduction/China_A_share_market_tushare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ShYRMdBTFLp",
   "metadata": {
    "id": "3ShYRMdBTFLp"
   },
   "source": [
    "## Quantitative trading in China A stock market with FinRL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pBU3DdPFTFLp",
   "metadata": {
    "id": "pBU3DdPFTFLp"
   },
   "source": [
    "Install FinRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51W37k2_TFLq",
   "metadata": {
    "id": "51W37k2_TFLq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ZmuaPTCTFLr",
   "metadata": {
    "id": "9ZmuaPTCTFLr"
   },
   "source": [
    "Install other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "q6T3o9yTTFLr",
   "metadata": {
    "id": "q6T3o9yTTFLr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install stockstats\n",
    "# !pip install tushare\n",
    "# #install talib\n",
    "# !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz \n",
    "# !tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "# import os\n",
    "# os.chdir('ta-lib') \n",
    "# !./configure --prefix=/usr\n",
    "# !make\n",
    "# !make install\n",
    "# #!sudo make install # Sometimes it need root \n",
    "# os.chdir('../')\n",
    "# !pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "DrReji1OTFLr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrReji1OTFLr",
    "outputId": "325c38e3-ca71-4b58-e0be-104e15011fe2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %cd /\n",
    "# !git clone https://github.com/AI4Finance-Foundation/FinRL-Meta\n",
    "# %cd /FinRL-Meta/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C-MYxgpJTMGP",
   "metadata": {
    "id": "C-MYxgpJTMGP"
   },
   "source": [
    "##Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Vx_hcZwgTKQp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vx_hcZwgTKQp",
    "outputId": "d6b36801-3064-4251-aadd-2396cb03ad5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL Modules have been imported!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "\n",
    "display.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from typing import List\n",
    "\n",
    "import pyfolio\n",
    "from pyfolio import timeseries\n",
    "\n",
    "from agents.stablebaselines3_models import DRLAgent\n",
    "from main import check_and_make_directories\n",
    "from meta import config\n",
    "from meta.config import (ALPACA_API_BASE_URL, ALPACA_API_KEY,\n",
    "                         ALPACA_API_SECRET, DATA_SAVE_DIR, ERL_PARAMS,\n",
    "                         INDICATORS, RESULTS_DIR, SAC_PARAMS,\n",
    "                         TENSORBOARD_LOG_DIR, TEST_END_DATE, TEST_START_DATE,\n",
    "                         TRADE_END_DATE, TRADE_START_DATE, TRAIN_END_DATE,\n",
    "                         TRAIN_START_DATE, TRAINED_MODEL_DIR, RLlib_PARAMS)\n",
    "from meta.config_tickers import DOW_30_TICKER\n",
    "from meta.data_processor import DataProcessor\n",
    "from meta.data_processors.tushare import ReturnPlotter, Tushare\n",
    "from meta.data_processors.tushare_private import ReturnPlotterPrivate\n",
    "from meta.env_stock_trading.env_stocktrading_China_A_shares import \\\n",
    "    StockTradingEnv\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "print(\"ALL Modules have been imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FRQz2ptSTjPJ",
   "metadata": {
    "id": "FRQz2ptSTjPJ"
   },
   "source": [
    "##Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pmttRZWWTXcd",
   "metadata": {
    "id": "pmttRZWWTXcd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' \n",
    "use check_and_make_directories() to replace the following\n",
    "\n",
    "if not os.path.exists(\"./datasets\"): \n",
    "  os.makedirs(\"./datasets\") \n",
    "if not os.path.exists(\"./trained_models\"): \n",
    "  os.makedirs(\"./trained_models\") \n",
    "if not os.path.exists(\"./tensorboard_log\"): \n",
    "  os.makedirs(\"./tensorboard_log\") \n",
    "if not os.path.exists(\"./results\"): \n",
    "  os.makedirs(\"./results\") \n",
    "'''\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94s2JtmxTuLq",
   "metadata": {
    "id": "94s2JtmxTuLq"
   },
   "source": [
    "##Download data, cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4906e9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "tushare successfully connected\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import meta\n",
    "from meta.local.selector.stock_selector import StockSelector\n",
    "\n",
    "importlib.reload(meta.local.selector.stock_selector)\n",
    "\n",
    "stock_sel = StockSelector()\n",
    "ticker_list = stock_sel.select_stocks()\n",
    "print(len(ticker_list))\n",
    "\n",
    "TRAIN_START_DATE = '2015-01-01' \n",
    "TRAIN_END_DATE= '2022-05-01'  \n",
    "TRADE_START_DATE = '2022-05-01' \n",
    "TRADE_END_DATE = '2022-10-27'\n",
    "\n",
    "TIME_INTERVAL = \"1d\" \n",
    "kwargs = {} \n",
    "kwargs['token'] = '27080ec403c0218f96f388bca1b1d85329d563c91a43672239619ef5'\n",
    "p = DataProcessor(data_source='tushare', start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, time_interval=TIME_INTERVAL, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "svZh2OT0T7PG",
   "metadata": {
    "id": "svZh2OT0T7PG"
   },
   "source": [
    "###Download and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "v_PzruLIT3D1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_PzruLIT3D1",
    "outputId": "fa4b9030-f8ff-41a3-abef-77be4f9d37ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:10<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (23514, 8)\n",
      "Shape of DataFrame:  (26614, 8)\n"
     ]
    }
   ],
   "source": [
    "p.download_data(ticker_list=ticker_list)\n",
    "\n",
    "p.clean_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tsHu-XT_T_vQ",
   "metadata": {
    "id": "tsHu-XT_T_vQ"
   },
   "source": [
    "###Add technical indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "VfniyyQQT3nq",
   "metadata": {
    "id": "VfniyyQQT3nq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Shape of DataFrame:  (13706, 17)\n"
     ]
    }
   ],
   "source": [
    "p.add_technical_indicator(config.INDICATORS) \n",
    "p.clean_data()\n",
    "\n",
    "#print(f\"p.dataframe: {p.dataframe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cKZk3jGuUR34",
   "metadata": {
    "id": "cKZk3jGuUR34"
   },
   "source": [
    "##Split training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "SuKbrwflUVeU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuKbrwflUVeU",
    "outputId": "7596367b-670d-4d6c-b439-033075d87589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train.tic.unique()): 14\n"
     ]
    }
   ],
   "source": [
    "train = p.data_split(p.dataframe, TRAIN_START_DATE, TRAIN_END_DATE) \n",
    "\n",
    "print(f\"len(train.tic.unique()): {len(train.tic.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ONAnSMBUWyu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ONAnSMBUWyu",
    "outputId": "5bdf45d0-7689-4d31-dfa6-cbcbe8e64827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.tic.unique(): ['000651.SZ' '002241.SZ' '002466.SZ' '300750.SZ' '300760.SZ' '600009.SH'\n",
      " '600036.SH' '600276.SH' '600438.SH' '600519.SH' '600740.SH' '601088.SH'\n",
      " '603259.SH' '603288.SH']\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.tic.unique(): {train.tic.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "BXF8hYDvUXfv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXF8hYDvUXfv",
    "outputId": "a08ebe19-0107-4e31-c6df-816c846aa3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.head():          tic        date  index   open   high    low  close     volume  day  \\\n",
      "0  000651.SZ  2018-10-17  12908  38.80  38.89  37.55  38.45  413250.35  2.0   \n",
      "0  002241.SZ  2018-10-17  12909   6.85   6.91   6.62   6.83  149395.37  2.0   \n",
      "0  002466.SZ  2018-10-17  12910  29.70  29.85  26.75  28.83  246876.87  2.0   \n",
      "0  300750.SZ  2018-10-17  12911  69.77  71.78  69.21  70.00  142321.65  2.0   \n",
      "0  300760.SZ  2018-10-17  12912  77.30  77.30  77.30  77.30    1865.47  2.0   \n",
      "\n",
      "       macd    boll_ub    boll_lb      rsi_30       cci_30       dx_30  \\\n",
      "0 -0.164248  40.521444  35.820556   46.431272    10.530756   10.666325   \n",
      "0 -0.445199   9.199594   6.777406   32.168754  -218.319107   66.894205   \n",
      "0 -2.192112  41.589158  27.700842   30.938485  -195.338539   45.520852   \n",
      "0 -0.050405  74.092877  60.518123   52.824871    79.289388    9.808731   \n",
      "0  0.560798  73.765412  67.477588  100.000000  1000.000000  100.000000   \n",
      "\n",
      "   close_30_sma  close_60_sma  \n",
      "0     38.136333     39.785833  \n",
      "0      8.241000      8.629000  \n",
      "0     34.945000     38.975667  \n",
      "0     66.406667     70.514000  \n",
      "0     70.504333     70.387167  \n"
     ]
    }
   ],
   "source": [
    "print(f\"train.head(): {train.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "CnwNoBG5UXSQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnwNoBG5UXSQ",
    "outputId": "3bcf1c7a-e9de-4b92-fc7e-069904d9e6e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (12040, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.shape: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joNhXi_ZUXId",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joNhXi_ZUXId",
    "outputId": "460b9763-6b0f-4976-f772-4a9a7cda2255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 14, State Space: 141\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique()) \n",
    "state_space = stock_dimension * (len(config.INDICATORS) + 2) + 1 \n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "le09273cUmzH",
   "metadata": {
    "id": "le09273cUmzH"
   },
   "source": [
    "##Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Npwpqkr7UpFF",
   "metadata": {
    "id": "Npwpqkr7UpFF"
   },
   "outputs": [],
   "source": [
    "env_kwargs = { \"stock_dim\": stock_dimension, \"hmax\": 1000, \"initial_amount\": 1000000, \"buy_cost_pct\": 6.87e-5, \"sell_cost_pct\": 1.0687e-3, \"reward_scaling\": 1e-4, \"state_space\": state_space, \"action_space\": stock_dimension, \"tech_indicator_list\": config.INDICATORS, \"print_verbosity\": 1, \"initial_buy\": True, \"hundred_each_trade\": True }\n",
    "\n",
    "e_train_gym = StockTradingEnv(df=train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1POZL3nUyDY",
   "metadata": {
    "id": "f1POZL3nUyDY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "print(type(env_train)): None\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env() \n",
    "\n",
    "print(f\"print(type(env_train)): {print(type(env_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QkY8sVWhU6PH",
   "metadata": {
    "id": "QkY8sVWhU6PH"
   },
   "source": [
    "###DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dLjEviBhUzuc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLjEviBhUzuc",
    "outputId": "58226aaa-41dc-45ce-9f5c-1e5cb94d27a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256, 'buffer_size': 50000, 'learning_rate': 0.0005, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1])}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_12\n",
      "Episode: 74\n",
      "day: 859, episode: 74\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1441096.76\n",
      "total_reward: 441096.76\n",
      "total_cost: 15602.93\n",
      "total_trades: 12025\n",
      "Sharpe: 0.497\n",
      "=================================\n",
      "Episode: 75\n",
      "day: 859, episode: 75\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1417111.56\n",
      "total_reward: 417111.56\n",
      "total_cost: 1710.44\n",
      "total_trades: 12026\n",
      "Sharpe: 0.495\n",
      "=================================\n",
      "Episode: 76\n",
      "day: 859, episode: 76\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1151263.00\n",
      "total_reward: 151263.00\n",
      "total_cost: 609.00\n",
      "total_trades: 12026\n",
      "Sharpe: 0.294\n",
      "=================================\n",
      "Episode: 77\n",
      "day: 859, episode: 77\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1109385.61\n",
      "total_reward: 109385.61\n",
      "total_cost: 619.39\n",
      "total_trades: 12026\n",
      "Sharpe: 0.255\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 65          |\n",
      "|    time_elapsed    | 52          |\n",
      "|    total_timesteps | 3440        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -332        |\n",
      "|    critic_loss     | 251         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 2580        |\n",
      "|    reward          | -0.27355927 |\n",
      "------------------------------------\n",
      "Episode: 78\n",
      "day: 859, episode: 78\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1133908.02\n",
      "total_reward: 133908.02\n",
      "total_cost: 606.98\n",
      "total_trades: 12026\n",
      "Sharpe: 0.279\n",
      "=================================\n",
      "Episode: 79\n",
      "day: 859, episode: 79\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1131527.39\n",
      "total_reward: 131527.39\n",
      "total_cost: 625.61\n",
      "total_trades: 12026\n",
      "Sharpe: 0.276\n",
      "=================================\n",
      "Episode: 80\n",
      "day: 859, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1143796.57\n",
      "total_reward: 143796.57\n",
      "total_cost: 606.43\n",
      "total_trades: 12026\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "Episode: 81\n",
      "day: 859, episode: 81\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1139561.09\n",
      "total_reward: 139561.09\n",
      "total_cost: 618.91\n",
      "total_trades: 12026\n",
      "Sharpe: 0.286\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 65         |\n",
      "|    time_elapsed    | 104        |\n",
      "|    total_timesteps | 6880       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -215       |\n",
      "|    critic_loss     | 144        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 6020       |\n",
      "|    reward          | -0.5423313 |\n",
      "-----------------------------------\n",
      "Episode: 82\n",
      "day: 859, episode: 82\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1113165.79\n",
      "total_reward: 113165.79\n",
      "total_cost: 619.21\n",
      "total_trades: 12026\n",
      "Sharpe: 0.260\n",
      "=================================\n",
      "Episode: 83\n",
      "day: 859, episode: 83\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1129163.72\n",
      "total_reward: 129163.72\n",
      "total_cost: 600.28\n",
      "total_trades: 12026\n",
      "Sharpe: 0.273\n",
      "=================================\n",
      "Episode: 84\n",
      "day: 859, episode: 84\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1149075.34\n",
      "total_reward: 149075.34\n",
      "total_cost: 602.66\n",
      "total_trades: 12026\n",
      "Sharpe: 0.293\n",
      "=================================\n",
      "Episode: 85\n",
      "day: 859, episode: 85\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1129317.56\n",
      "total_reward: 129317.56\n",
      "total_cost: 619.44\n",
      "total_trades: 12026\n",
      "Sharpe: 0.274\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 65         |\n",
      "|    time_elapsed    | 157        |\n",
      "|    total_timesteps | 10320      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -152       |\n",
      "|    critic_loss     | 31.6       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 9460       |\n",
      "|    reward          | -0.3991153 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env=env_train) \n",
    "DDPG_PARAMS = { \"batch_size\": 256, \"buffer_size\": 50000, \"learning_rate\": 0.0005, \"action_noise\": \"normal\", } \n",
    "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300])) \n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs=DDPG_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
    "\n",
    "trained_ddpg = agent.train_model(model=model_ddpg, tb_log_name='ddpg', total_timesteps=10000, n_eval_episodes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ALJ1gqVmVEiU",
   "metadata": {
    "id": "ALJ1gqVmVEiU"
   },
   "source": [
    "###A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2F5qCGnNUzm7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2F5qCGnNUzm7",
    "outputId": "b8db239f-7d37-4587-c511-0f2dc4c6f273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_10\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 137       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -19.8     |\n",
      "|    explained_variance | 0.0482    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 47.9      |\n",
      "|    reward             | -3.474607 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 39.6      |\n",
      "-------------------------------------\n",
      "Episode: 87\n",
      "day: 859, episode: 87\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2685123.56\n",
      "total_reward: 1685123.56\n",
      "total_cost: 195513.36\n",
      "total_trades: 12021\n",
      "Sharpe: 1.200\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 121         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | 0.277       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -71.4       |\n",
      "|    reward             | -0.15988307 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 12.8        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 126        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.9      |\n",
      "|    explained_variance | -3.35      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | 3.67       |\n",
      "|    reward             | 0.56268936 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.39       |\n",
      "--------------------------------------\n",
      "Episode: 88\n",
      "day: 859, episode: 88\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 798860.14\n",
      "total_reward: -201139.86\n",
      "total_cost: 114831.86\n",
      "total_trades: 12022\n",
      "Sharpe: 0.164\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 140         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | -0.331      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -8.17       |\n",
      "|    reward             | -0.73293775 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.721       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 154        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.9      |\n",
      "|    explained_variance | -0.0604    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -26.9      |\n",
      "|    reward             | -2.7708378 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 2.62       |\n",
      "--------------------------------------\n",
      "Episode: 89\n",
      "day: 859, episode: 89\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 736286.19\n",
      "total_reward: -263713.81\n",
      "total_cost: 108158.81\n",
      "total_trades: 12018\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 167       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -19.9     |\n",
      "|    explained_variance | -7.31     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 7.09      |\n",
      "|    reward             | 1.1391066 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.269     |\n",
      "-------------------------------------\n",
      "Episode: 90\n",
      "day: 859, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 902050.31\n",
      "total_reward: -97949.69\n",
      "total_cost: 120729.69\n",
      "total_trades: 12013\n",
      "Sharpe: 0.277\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 180         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20         |\n",
      "|    explained_variance | 0.61        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 51.4        |\n",
      "|    reward             | -0.10396692 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 6.27        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 190        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20        |\n",
      "|    explained_variance | -0.18      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 76.2       |\n",
      "|    reward             | -1.0195487 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 23.3       |\n",
      "--------------------------------------\n",
      "Episode: 91\n",
      "day: 859, episode: 91\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1358735.48\n",
      "total_reward: 358735.48\n",
      "total_cost: 173885.52\n",
      "total_trades: 12017\n",
      "Sharpe: 0.475\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20        |\n",
      "|    explained_variance | -0.165     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | -33.7      |\n",
      "|    reward             | -0.6951531 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.9        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 208         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | -0.025      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -12.9       |\n",
      "|    reward             | -0.44731915 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.945       |\n",
      "---------------------------------------\n",
      "Episode: 92\n",
      "day: 859, episode: 92\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 557995.08\n",
      "total_reward: -442004.92\n",
      "total_cost: 59897.92\n",
      "total_trades: 12021\n",
      "Sharpe: -0.046\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | 0.262       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 32.5        |\n",
      "|    reward             | -0.70044154 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | -0.0389     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 1.35        |\n",
      "|    reward             | -0.55211943 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "Episode: 93\n",
      "day: 859, episode: 93\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 602039.96\n",
      "total_reward: -397960.04\n",
      "total_cost: 65891.04\n",
      "total_trades: 12014\n",
      "Sharpe: -0.009\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 227      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -20.1    |\n",
      "|    explained_variance | -0.199   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -46.6    |\n",
      "|    reward             | 1.634822 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.43     |\n",
      "------------------------------------\n",
      "Episode: 94\n",
      "day: 859, episode: 94\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 859204.74\n",
      "total_reward: -140795.26\n",
      "total_cost: 98708.26\n",
      "total_trades: 12020\n",
      "Sharpe: 0.128\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 232         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | -14.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -30.3       |\n",
      "|    reward             | -0.15291174 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 237       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.2     |\n",
      "|    explained_variance | -0.0255   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 16.7      |\n",
      "|    reward             | -8.028721 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 7.45      |\n",
      "-------------------------------------\n",
      "Episode: 95\n",
      "day: 859, episode: 95\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1237029.56\n",
      "total_reward: 237029.56\n",
      "total_cost: 165433.44\n",
      "total_trades: 12011\n",
      "Sharpe: 0.373\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 240        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.2      |\n",
      "|    explained_variance | -0.0773    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 60.4       |\n",
      "|    reward             | -1.4293888 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 9.32       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 243         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 34          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.2       |\n",
      "|    explained_variance | -0.0971     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 23.4        |\n",
      "|    reward             | -0.11596956 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 5.05        |\n",
      "---------------------------------------\n",
      "Episode: 96\n",
      "day: 859, episode: 96\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1051029.63\n",
      "total_reward: 51029.63\n",
      "total_cost: 151612.37\n",
      "total_trades: 12021\n",
      "Sharpe: 0.280\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 247        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 36         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.2      |\n",
      "|    explained_variance | 0.0237     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 40.6       |\n",
      "|    reward             | -0.3622488 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 5.94       |\n",
      "--------------------------------------\n",
      "Episode: 97\n",
      "day: 859, episode: 97\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 643020.81\n",
      "total_reward: -356979.19\n",
      "total_cost: 118832.19\n",
      "total_trades: 12014\n",
      "Sharpe: 0.042\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 249         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.2       |\n",
      "|    explained_variance | -0.0711     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | 26.3        |\n",
      "|    reward             | -0.10833998 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 4.45        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 249       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.2     |\n",
      "|    explained_variance | -0.0576   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 64.1      |\n",
      "|    reward             | 4.3793287 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 15.6      |\n",
      "-------------------------------------\n",
      "Episode: 98\n",
      "day: 859, episode: 98\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1517989.37\n",
      "total_reward: 517989.37\n",
      "total_cost: 23754.63\n",
      "total_trades: 12016\n",
      "Sharpe: 0.554\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 251        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.3      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | 9.52       |\n",
      "|    reward             | -0.3972938 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.25       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 252       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.3     |\n",
      "|    explained_variance | 0.0217    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 74.9      |\n",
      "|    reward             | 1.7547086 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 15.4      |\n",
      "-------------------------------------\n",
      "Episode: 99\n",
      "day: 859, episode: 99\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1341495.23\n",
      "total_reward: 341495.23\n",
      "total_cost: 95208.77\n",
      "total_trades: 12019\n",
      "Sharpe: 0.436\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 254       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.3     |\n",
      "|    explained_variance | -0.0218   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -38.9     |\n",
      "|    reward             | 1.2331842 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 8.07      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 256         |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.4       |\n",
      "|    explained_variance | -0.133      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | -95.4       |\n",
      "|    reward             | -0.08808486 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 22.4        |\n",
      "---------------------------------------\n",
      "Episode: 100\n",
      "day: 859, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1315077.49\n",
      "total_reward: 315077.49\n",
      "total_cost: 98901.51\n",
      "total_trades: 12014\n",
      "Sharpe: 0.515\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 258        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | 52.1       |\n",
      "|    reward             | -4.0038567 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 6.45       |\n",
      "--------------------------------------\n",
      "Episode: 101\n",
      "day: 859, episode: 101\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1146532.57\n",
      "total_reward: 146532.57\n",
      "total_cost: 209903.43\n",
      "total_trades: 12023\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 259        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.4      |\n",
      "|    explained_variance | -0.0666    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | -23.5      |\n",
      "|    reward             | 0.37952724 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 1.5        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 260        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.4      |\n",
      "|    explained_variance | 0.00511    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -2.01      |\n",
      "|    reward             | -1.0190475 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.652      |\n",
      "--------------------------------------\n",
      "Episode: 102\n",
      "day: 859, episode: 102\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 591679.27\n",
      "total_reward: -408320.73\n",
      "total_cost: 100527.73\n",
      "total_trades: 12014\n",
      "Sharpe: -0.062\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.4     |\n",
      "|    explained_variance | -1.47     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -13.9     |\n",
      "|    reward             | 0.3533025 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.654     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 263         |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.4       |\n",
      "|    explained_variance | -0.023      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | -8.96       |\n",
      "|    reward             | -0.30748826 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "Episode: 103\n",
      "day: 859, episode: 103\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 825536.12\n",
      "total_reward: -174463.88\n",
      "total_cost: 89741.88\n",
      "total_trades: 12015\n",
      "Sharpe: 0.087\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 56         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.5      |\n",
      "|    explained_variance | 0.0467     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | 70.3       |\n",
      "|    reward             | -0.6191981 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 14         |\n",
      "--------------------------------------\n",
      "Episode: 104\n",
      "day: 859, episode: 104\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1735607.25\n",
      "total_reward: 735607.25\n",
      "total_cost: 116040.75\n",
      "total_trades: 12018\n",
      "Sharpe: 0.765\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 263          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 58           |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.5        |\n",
      "|    explained_variance | -0.621       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | 37           |\n",
      "|    reward             | 0.0017749158 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 6.83         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 265       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.4     |\n",
      "|    explained_variance | -0.473    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -12.1     |\n",
      "|    reward             | -0.309535 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 2.28      |\n",
      "-------------------------------------\n",
      "Episode: 105\n",
      "day: 859, episode: 105\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1261900.05\n",
      "total_reward: 261900.05\n",
      "total_cost: 117645.95\n",
      "total_trades: 12020\n",
      "Sharpe: 0.461\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 267         |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.5       |\n",
      "|    explained_variance | -0.0701     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | -2.65       |\n",
      "|    reward             | -0.42956033 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.0906      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.5     |\n",
      "|    explained_variance | 0.18      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 25.9      |\n",
      "|    reward             | 1.4060473 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 3.42      |\n",
      "-------------------------------------\n",
      "Episode: 106\n",
      "day: 859, episode: 106\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 946029.62\n",
      "total_reward: -53970.38\n",
      "total_cost: 97416.38\n",
      "total_trades: 12020\n",
      "Sharpe: 0.192\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 269          |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 64           |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.5        |\n",
      "|    explained_variance | -2           |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | 16.1         |\n",
      "|    reward             | -0.020042552 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.71         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 271         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 66          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.5       |\n",
      "|    explained_variance | -0.00127    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | 27.7        |\n",
      "|    reward             | 0.038754337 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 2.34        |\n",
      "---------------------------------------\n",
      "Episode: 107\n",
      "day: 859, episode: 107\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 707798.59\n",
      "total_reward: -292201.41\n",
      "total_cost: 36762.41\n",
      "total_trades: 12024\n",
      "Sharpe: 0.104\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 270        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.5      |\n",
      "|    explained_variance | -0.000627  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | -15        |\n",
      "|    reward             | -1.1351357 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 1.1        |\n",
      "--------------------------------------\n",
      "Episode: 108\n",
      "day: 859, episode: 108\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 894893.41\n",
      "total_reward: -105106.59\n",
      "total_cost: 19699.59\n",
      "total_trades: 12021\n",
      "Sharpe: 0.091\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 271        |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.6      |\n",
      "|    explained_variance | -0.325     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | 30.7       |\n",
      "|    reward             | -1.1763031 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 2.62       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 272        |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.6      |\n",
      "|    explained_variance | -0.0443    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | -49.8      |\n",
      "|    reward             | -2.5484486 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 9.1        |\n",
      "--------------------------------------\n",
      "Episode: 109\n",
      "day: 859, episode: 109\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1090512.01\n",
      "total_reward: 90512.01\n",
      "total_cost: 25052.99\n",
      "total_trades: 12021\n",
      "Sharpe: 0.267\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 273        |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 73         |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.6      |\n",
      "|    explained_variance | -0.233     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | 2.53       |\n",
      "|    reward             | 0.07024276 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.188      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 274       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.6     |\n",
      "|    explained_variance | 0.0171    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | -148      |\n",
      "|    reward             | 0.3833866 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 86.8      |\n",
      "-------------------------------------\n",
      "Episode: 110\n",
      "day: 859, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1138018.85\n",
      "total_reward: 138018.85\n",
      "total_cost: 38043.15\n",
      "total_trades: 12019\n",
      "Sharpe: 0.386\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 275        |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.6      |\n",
      "|    explained_variance | -0.6       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | -2.12      |\n",
      "|    reward             | -0.6938073 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.514      |\n",
      "--------------------------------------\n",
      "Episode: 111\n",
      "day: 859, episode: 111\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1809980.06\n",
      "total_reward: 809980.06\n",
      "total_cost: 68596.94\n",
      "total_trades: 12021\n",
      "Sharpe: 0.654\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -20.7    |\n",
      "|    explained_variance | 0.152    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -226     |\n",
      "|    reward             | 2.274617 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 121      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.6     |\n",
      "|    explained_variance | 0.000725  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 54.4      |\n",
      "|    reward             | -5.985124 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 25.1      |\n",
      "-------------------------------------\n",
      "Episode: 112\n",
      "day: 859, episode: 112\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1946365.84\n",
      "total_reward: 946365.84\n",
      "total_cost: 28502.16\n",
      "total_trades: 12021\n",
      "Sharpe: 0.662\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 278         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.6       |\n",
      "|    explained_variance | -0.407      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | -7.97       |\n",
      "|    reward             | -0.84921783 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 279        |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 82         |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.6      |\n",
      "|    explained_variance | -0.000196  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | -105       |\n",
      "|    reward             | -0.9244414 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 41         |\n",
      "--------------------------------------\n",
      "Episode: 113\n",
      "day: 859, episode: 113\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1654726.73\n",
      "total_reward: 654726.73\n",
      "total_cost: 30522.27\n",
      "total_trades: 12024\n",
      "Sharpe: 0.583\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 280        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 83         |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.6      |\n",
      "|    explained_variance | 0.0336     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | 60.9       |\n",
      "|    reward             | -1.5533699 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 9.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 280       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.6     |\n",
      "|    explained_variance | -0.024    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | -92.7     |\n",
      "|    reward             | 2.6173737 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 63.2      |\n",
      "-------------------------------------\n",
      "Episode: 114\n",
      "day: 859, episode: 114\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2778850.79\n",
      "total_reward: 1778850.79\n",
      "total_cost: 54193.21\n",
      "total_trades: 12022\n",
      "Sharpe: 0.945\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 281      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -20.6    |\n",
      "|    explained_variance | 0.403    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 48.9     |\n",
      "|    reward             | 1.006988 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 5.35     |\n",
      "------------------------------------\n",
      "Episode: 115\n",
      "day: 859, episode: 115\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1164058.66\n",
      "total_reward: 164058.66\n",
      "total_cost: 33712.34\n",
      "total_trades: 12022\n",
      "Sharpe: 0.309\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 281          |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | -1.05        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | 22.7         |\n",
      "|    reward             | 0.0011510379 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 1.33         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.6     |\n",
      "|    explained_variance | 0.0833    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 126       |\n",
      "|    reward             | -3.801491 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 46.1      |\n",
      "-------------------------------------\n",
      "Episode: 116\n",
      "day: 859, episode: 116\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1118779.02\n",
      "total_reward: 118779.02\n",
      "total_cost: 78179.98\n",
      "total_trades: 12019\n",
      "Sharpe: 0.388\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 281         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | -2.28       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | -29         |\n",
      "|    reward             | -0.32627484 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 2.62        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 282       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.7     |\n",
      "|    explained_variance | 0.203     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 71.9      |\n",
      "|    reward             | 3.4224901 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "Episode: 117\n",
      "day: 859, episode: 117\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 968192.00\n",
      "total_reward: -31808.00\n",
      "total_cost: 99632.00\n",
      "total_trades: 12024\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 282        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 95         |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.7      |\n",
      "|    explained_variance | -0.295     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | 3.95       |\n",
      "|    reward             | -0.5299667 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.44       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 97         |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.6      |\n",
      "|    explained_variance | 0.272      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | -26.8      |\n",
      "|    reward             | -1.9096813 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.42       |\n",
      "--------------------------------------\n",
      "Episode: 118\n",
      "day: 859, episode: 118\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 791122.48\n",
      "total_reward: -208877.52\n",
      "total_cost: 98156.52\n",
      "total_trades: 12023\n",
      "Sharpe: 0.108\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 282        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 98         |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.7      |\n",
      "|    explained_variance | -1.72      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | -17.6      |\n",
      "|    reward             | 0.90070426 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.916      |\n",
      "--------------------------------------\n",
      "Episode: 119\n",
      "day: 859, episode: 119\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 536117.93\n",
      "total_reward: -463882.07\n",
      "total_cost: 74847.07\n",
      "total_trades: 12020\n",
      "Sharpe: -0.125\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 100          |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | 0.1          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | 23.5         |\n",
      "|    reward             | -0.015332546 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 2.47         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.6      |\n",
      "|    explained_variance | 0.165      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | -28.1      |\n",
      "|    reward             | -1.9827414 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 3.19       |\n",
      "--------------------------------------\n",
      "Episode: 120\n",
      "day: 859, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 964360.25\n",
      "total_reward: -35639.75\n",
      "total_cost: 80169.75\n",
      "total_trades: 12024\n",
      "Sharpe: 0.285\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 104        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.6      |\n",
      "|    explained_variance | -0.179     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | -15.7      |\n",
      "|    reward             | -1.9517301 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.7        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 284      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -20.6    |\n",
      "|    explained_variance | 0.201    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -10.6    |\n",
      "|    reward             | 2.357519 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.718    |\n",
      "------------------------------------\n",
      "Episode: 121\n",
      "day: 859, episode: 121\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1659080.58\n",
      "total_reward: 659080.58\n",
      "total_cost: 55639.42\n",
      "total_trades: 12023\n",
      "Sharpe: 0.608\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 284      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -20.6    |\n",
      "|    explained_variance | -0.0707  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 41.2     |\n",
      "|    reward             | 0.133495 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 5.49     |\n",
      "------------------------------------\n",
      "Episode: 122\n",
      "day: 859, episode: 122\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1410165.03\n",
      "total_reward: 410165.03\n",
      "total_cost: 59089.97\n",
      "total_trades: 12021\n",
      "Sharpe: 0.516\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 284        |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 108        |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.7      |\n",
      "|    explained_variance | 0.0288     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | 25.9       |\n",
      "|    reward             | 0.16820435 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 2.4        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.8     |\n",
      "|    explained_variance | -0.031    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 257       |\n",
      "|    reward             | 7.7966967 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 179       |\n",
      "-------------------------------------\n",
      "Episode: 123\n",
      "day: 859, episode: 123\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1503803.36\n",
      "total_reward: 503803.36\n",
      "total_cost: 57309.64\n",
      "total_trades: 12018\n",
      "Sharpe: 0.545\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.8     |\n",
      "|    explained_variance | -0.0419   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -7.6      |\n",
      "|    reward             | 1.5585926 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.963     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 284       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 114       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.8     |\n",
      "|    explained_variance | -0.0334   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -29.7     |\n",
      "|    reward             | 5.0715723 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 18.7      |\n",
      "-------------------------------------\n",
      "Episode: 124\n",
      "day: 859, episode: 124\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1120890.93\n",
      "total_reward: 120890.93\n",
      "total_cost: 42507.07\n",
      "total_trades: 12022\n",
      "Sharpe: 0.414\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 284      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -20.8    |\n",
      "|    explained_variance | 0.0691   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -3.94    |\n",
      "|    reward             | 4.120067 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 5.74     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 118        |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.8      |\n",
      "|    explained_variance | -0.0284    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | -47.3      |\n",
      "|    reward             | -1.5440031 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 6.38       |\n",
      "--------------------------------------\n",
      "Episode: 125\n",
      "day: 859, episode: 125\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1735266.59\n",
      "total_reward: 735266.59\n",
      "total_cost: 57945.41\n",
      "total_trades: 12019\n",
      "Sharpe: 0.614\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 284        |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 119        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.9      |\n",
      "|    explained_variance | -0.279     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 24.6       |\n",
      "|    reward             | -3.1834176 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 2.18       |\n",
      "--------------------------------------\n",
      "Episode: 126\n",
      "day: 859, episode: 126\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 820681.92\n",
      "total_reward: -179318.08\n",
      "total_cost: 79488.08\n",
      "total_trades: 12023\n",
      "Sharpe: 0.153\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 121        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.9      |\n",
      "|    explained_variance | -0.0991    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -34        |\n",
      "|    reward             | 0.27068096 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 2.77       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 284        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.9      |\n",
      "|    explained_variance | 0.0651     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 32.5       |\n",
      "|    reward             | -0.9382956 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 2.32       |\n",
      "--------------------------------------\n",
      "Episode: 127\n",
      "day: 859, episode: 127\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 565043.78\n",
      "total_reward: -434956.22\n",
      "total_cost: 60204.22\n",
      "total_trades: 12021\n",
      "Sharpe: -0.068\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 284        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.9      |\n",
      "|    explained_variance | 0.218      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | -12.9      |\n",
      "|    reward             | 0.10446952 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.781      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 284        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 126        |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.9      |\n",
      "|    explained_variance | -0.00889   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | -4.19      |\n",
      "|    reward             | -0.8628402 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 2.12       |\n",
      "--------------------------------------\n",
      "Episode: 128\n",
      "day: 859, episode: 128\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 832003.13\n",
      "total_reward: -167996.87\n",
      "total_cost: 60414.87\n",
      "total_trades: 12019\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21       |\n",
      "|    explained_variance | 0.0262    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 74.9      |\n",
      "|    reward             | 1.4421781 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "Episode: 129\n",
      "day: 859, episode: 129\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1079917.70\n",
      "total_reward: 79917.70\n",
      "total_cost: 110942.30\n",
      "total_trades: 12019\n",
      "Sharpe: 0.324\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 129        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21        |\n",
      "|    explained_variance | -0.0548    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | -4.9       |\n",
      "|    reward             | -1.2509848 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.364      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21       |\n",
      "|    explained_variance | -0.0608   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 20.1      |\n",
      "|    reward             | 0.6073027 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.44      |\n",
      "-------------------------------------\n",
      "Episode: 130\n",
      "day: 859, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 823092.20\n",
      "total_reward: -176907.80\n",
      "total_cost: 107160.80\n",
      "total_trades: 12023\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | 0.273       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | 1.27        |\n",
      "|    reward             | 0.034682553 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.0354      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21        |\n",
      "|    explained_variance | 0.13       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | 7.69       |\n",
      "|    reward             | 0.51271945 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.412      |\n",
      "--------------------------------------\n",
      "Episode: 131\n",
      "day: 859, episode: 131\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 537549.69\n",
      "total_reward: -462450.31\n",
      "total_cost: 92411.31\n",
      "total_trades: 12022\n",
      "Sharpe: -0.241\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 286       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 135       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21       |\n",
      "|    explained_variance | -4.67     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 23.3      |\n",
      "|    reward             | 0.5152242 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.34      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 287        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 137        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21        |\n",
      "|    explained_variance | -1.59      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | 22.8       |\n",
      "|    reward             | -1.0132039 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 1.54       |\n",
      "--------------------------------------\n",
      "Episode: 132\n",
      "day: 859, episode: 132\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 537596.30\n",
      "total_reward: -462403.70\n",
      "total_cost: 125456.70\n",
      "total_trades: 12023\n",
      "Sharpe: -0.241\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 287         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | -0.631      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 22          |\n",
      "|    reward             | -0.55049855 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "Episode: 133\n",
      "day: 859, episode: 133\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 586679.44\n",
      "total_reward: -413320.56\n",
      "total_cost: 149982.56\n",
      "total_trades: 12023\n",
      "Sharpe: -0.130\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 287         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | -0.0282     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 10.4        |\n",
      "|    reward             | -0.31570727 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 142        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21        |\n",
      "|    explained_variance | -0.304     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -37.1      |\n",
      "|    reward             | -1.5573912 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 5.72       |\n",
      "--------------------------------------\n",
      "Episode: 134\n",
      "day: 859, episode: 134\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 487814.59\n",
      "total_reward: -512185.41\n",
      "total_cost: 132829.41\n",
      "total_trades: 12026\n",
      "Sharpe: -0.255\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 288         |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | 0.0715      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | 21.3        |\n",
      "|    reward             | 0.026901327 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 145        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21        |\n",
      "|    explained_variance | -0.769     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | -2.01      |\n",
      "|    reward             | -0.4431776 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.477      |\n",
      "--------------------------------------\n",
      "Episode: 135\n",
      "day: 859, episode: 135\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 634024.49\n",
      "total_reward: -365975.51\n",
      "total_cost: 132532.51\n",
      "total_trades: 12025\n",
      "Sharpe: -0.015\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 289         |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.1       |\n",
      "|    explained_variance | -0.203      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | 0.398       |\n",
      "|    reward             | -0.20641401 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.0744      |\n",
      "---------------------------------------\n",
      "Episode: 136\n",
      "day: 859, episode: 136\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 465767.40\n",
      "total_reward: -534232.60\n",
      "total_cost: 84225.60\n",
      "total_trades: 12025\n",
      "Sharpe: -0.245\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 148        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.1      |\n",
      "|    explained_variance | -0.189     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | -71.2      |\n",
      "|    reward             | 0.18936582 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 10.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.2     |\n",
      "|    explained_variance | -0.0767   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 0.484     |\n",
      "|    reward             | -2.820522 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.71      |\n",
      "-------------------------------------\n",
      "Episode: 137\n",
      "day: 859, episode: 137\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 789868.95\n",
      "total_reward: -210131.05\n",
      "total_cost: 89989.05\n",
      "total_trades: 12021\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 290       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.2     |\n",
      "|    explained_variance | 0.0154    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | -43.9     |\n",
      "|    reward             | 0.1686081 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 7         |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 290          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 153          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | 0.143        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | 16.4         |\n",
      "|    reward             | -0.049595974 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 1.15         |\n",
      "----------------------------------------\n",
      "Episode: 138\n",
      "day: 859, episode: 138\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 648799.02\n",
      "total_reward: -351200.98\n",
      "total_cost: 133740.98\n",
      "total_trades: 12025\n",
      "Sharpe: -0.082\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 291         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.3       |\n",
      "|    explained_variance | -0.0161     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -23.5       |\n",
      "|    reward             | -0.11557735 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 291         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.3       |\n",
      "|    explained_variance | -0.377      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | -22         |\n",
      "|    reward             | -0.92402345 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 3.53        |\n",
      "---------------------------------------\n",
      "Episode: 139\n",
      "day: 859, episode: 139\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 467180.12\n",
      "total_reward: -532819.88\n",
      "total_cost: 117188.88\n",
      "total_trades: 12021\n",
      "Sharpe: -0.320\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 291        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.3      |\n",
      "|    explained_variance | -0.471     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | 36.1       |\n",
      "|    reward             | 0.60106915 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 2.72       |\n",
      "--------------------------------------\n",
      "Episode: 140\n",
      "day: 859, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 589540.06\n",
      "total_reward: -410459.94\n",
      "total_cost: 83194.94\n",
      "total_trades: 12024\n",
      "Sharpe: -0.175\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 291        |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 159        |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.3      |\n",
      "|    explained_variance | -0.589     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | 24         |\n",
      "|    reward             | 0.06524009 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 1.31       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 292        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 160        |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.2      |\n",
      "|    explained_variance | -0.13      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | 35.1       |\n",
      "|    reward             | -1.2517105 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 3.52       |\n",
      "--------------------------------------\n",
      "Episode: 141\n",
      "day: 859, episode: 141\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 610452.06\n",
      "total_reward: -389547.94\n",
      "total_cost: 78482.94\n",
      "total_trades: 12024\n",
      "Sharpe: -0.031\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 292        |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 162        |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.3      |\n",
      "|    explained_variance | -32.9      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | 7.6        |\n",
      "|    reward             | -0.1205999 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 2.26       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 292       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.2     |\n",
      "|    explained_variance | 0.602     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | 69.8      |\n",
      "|    reward             | 5.9820504 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 8.84      |\n",
      "-------------------------------------\n",
      "Episode: 142\n",
      "day: 859, episode: 142\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1234137.13\n",
      "total_reward: 234137.13\n",
      "total_cost: 57958.87\n",
      "total_trades: 12025\n",
      "Sharpe: 0.439\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 292         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | -0.985      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | 33.9        |\n",
      "|    reward             | -0.26101732 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 3.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 293        |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.2      |\n",
      "|    explained_variance | -0.0787    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | 23.4       |\n",
      "|    reward             | 0.49630642 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "Episode: 143\n",
      "day: 859, episode: 143\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 639086.74\n",
      "total_reward: -360913.26\n",
      "total_cost: 128182.26\n",
      "total_trades: 12024\n",
      "Sharpe: -0.014\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 293       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.2     |\n",
      "|    explained_variance | -0.00484  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -14.7     |\n",
      "|    reward             | 2.1850948 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.611     |\n",
      "-------------------------------------\n",
      "Episode: 144\n",
      "day: 859, episode: 144\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 726618.50\n",
      "total_reward: -273381.50\n",
      "total_cost: 147730.50\n",
      "total_trades: 12026\n",
      "Sharpe: -0.019\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 293         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | -0.767      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | 0.607       |\n",
      "|    reward             | -0.39152917 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.0847      |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env=env_train) \n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c', total_timesteps=50000, n_eval_episodes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ArAnGULyVVfK",
   "metadata": {
    "id": "ArAnGULyVVfK"
   },
   "source": [
    "##Trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "TzU6JBAWVGPG",
   "metadata": {
    "id": "TzU6JBAWVGPG"
   },
   "outputs": [],
   "source": [
    "trade = p.data_split(p.dataframe, TRADE_START_DATE, TRADE_END_DATE) \n",
    "env_kwargs = { \"stock_dim\": stock_dimension, \"hmax\": 1000, \"initial_amount\": 1000000, \"buy_cost_pct\": 6.87e-5, \"sell_cost_pct\": 1.0687e-3, \"reward_scaling\": 1e-4, \"state_space\": state_space, \"action_space\": stock_dimension, \"tech_indicator_list\": config.INDICATORS, \"print_verbosity\": 1, \"initial_buy\": False, \"hundred_each_trade\": True } \n",
    "e_trade_gym = StockTradingEnv(df=trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdg8qypiVSOn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdg8qypiVSOn",
    "outputId": "af6f6967-7e06-41c5-850f-d0e2512ecd43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\n",
      "day: 117, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 806683.72\n",
      "total_reward: -193316.28\n",
      "total_cost: 237.28\n",
      "total_trades: 361\n",
      "Sharpe: -1.180\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ddpg, environment=e_trade_gym)\n",
    "# import pickle\n",
    "# with open('./df_account_value.pickle', 'wb') as handle:\n",
    "#     pickle.dump(df_account_value, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86d82263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  account_value\n",
      "0    2022-05-05   1.000000e+06\n",
      "1    2022-05-06   9.943862e+05\n",
      "2    2022-05-09   9.886927e+05\n",
      "3    2022-05-10   1.002569e+06\n",
      "4    2022-05-11   1.017396e+06\n",
      "..          ...            ...\n",
      "113  2022-10-20   8.249397e+05\n",
      "114  2022-10-21   8.093197e+05\n",
      "115  2022-10-24   7.807317e+05\n",
      "116  2022-10-25   7.738837e+05\n",
      "117  2022-10-26   8.066837e+05\n",
      "\n",
      "[118 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_account_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "Ih4rdH3uVSo1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ih4rdH3uVSo1",
    "outputId": "291d8234-ee54-4ef2-a511-1e084a783f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_actions:             000651.SZ  002241.SZ  002466.SZ  300750.SZ  300760.SZ  600009.SH  \\\n",
      "date                                                                           \n",
      "2022-05-05       1000          0          0          0          0          0   \n",
      "2022-05-06       1000          0          0          0          0          0   \n",
      "2022-05-09       1000          0          0          0          0          0   \n",
      "2022-05-10       1000          0          0          0          0          0   \n",
      "2022-05-11       1000          0          0          0          0          0   \n",
      "...               ...        ...        ...        ...        ...        ...   \n",
      "2022-10-19          0          0          0          0          0          0   \n",
      "2022-10-20          0          0          0          0          0          0   \n",
      "2022-10-21          0          0          0          0          0          0   \n",
      "2022-10-24          0          0          0          0          0          0   \n",
      "2022-10-25          0          0          0          0          0          0   \n",
      "\n",
      "            600036.SH  600276.SH  600438.SH  600519.SH  600740.SH  601088.SH  \\\n",
      "date                                                                           \n",
      "2022-05-05       1000       1000          0          0          0          0   \n",
      "2022-05-06       1000       1000          0          0          0          0   \n",
      "2022-05-09       1000       1000          0          0          0          0   \n",
      "2022-05-10       1000       1000          0          0          0          0   \n",
      "2022-05-11       1000       1000          0          0          0          0   \n",
      "...               ...        ...        ...        ...        ...        ...   \n",
      "2022-10-19          0          0          0          0          0          0   \n",
      "2022-10-20          0          0          0          0          0          0   \n",
      "2022-10-21          0          0          0          0          0          0   \n",
      "2022-10-24          0          0          0          0          0          0   \n",
      "2022-10-25          0          0          0          0          0          0   \n",
      "\n",
      "            603259.SH  603288.SH  \n",
      "date                              \n",
      "2022-05-05       1000          0  \n",
      "2022-05-06       1000          0  \n",
      "2022-05-09       1000          0  \n",
      "2022-05-10       1000          0  \n",
      "2022-05-11       1000          0  \n",
      "...               ...        ...  \n",
      "2022-10-19          0          0  \n",
      "2022-10-20          0          0  \n",
      "2022-10-21          0          0  \n",
      "2022-10-24          0          0  \n",
      "2022-10-25          0          0  \n",
      "\n",
      "[117 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "df_actions.to_csv(\"action.csv\", index=False) \n",
    "print(f\"df_actions: {df_actions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l7X1KIaVWUYp",
   "metadata": {
    "id": "l7X1KIaVWUYp"
   },
   "source": [
    "##Backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dUJn8einWPKI",
   "metadata": {
    "id": "dUJn8einWPKI"
   },
   "source": [
    "###matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pR6hNouKWOoY",
   "metadata": {
    "id": "pR6hNouKWOoY"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import meta.data_processors.tushare_private\n",
    "importlib.reload(meta.data_processors.tushare_private)\n",
    "from meta.data_processors.tushare_private import ReturnPlotterPrivate, TICKET_TYPE_INDEX, TICKET_TYPE_TICKET\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plotter = ReturnPlotterPrivate(df_account_value, trade, TRADE_START_DATE, TRADE_END_DATE)\n",
    "plotter.plot(figure_filepath=\"./China_A_share.png\")\n",
    "# plotter.plot()\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "Qx62Q575YC9I",
   "metadata": {
    "id": "Qx62Q575YC9I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TICKET_TYPE_INDEX\n"
     ]
    }
   ],
   "source": [
    "# ticket: SSE 50：000016.SH\n",
    "baseline_ticket = \"000016.SH\"\n",
    "plotter.plot(baseline_ticket, figure_filepath=\"./China_A_share_vs_{0}.png\".format(baseline_ticket), ticket_type=TICKET_TYPE_INDEX)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XUAh2S9Lamxe",
   "metadata": {
    "id": "XUAh2S9Lamxe"
   },
   "source": [
    "###CSI 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ZSRJpKINYcBa",
   "metadata": {
    "id": "ZSRJpKINYcBa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TICKET_TYPE_INDEX\n",
      "baseline_df         ts_code trade_date      close       open       high        low  \\\n",
      "0    399300.SZ   20221027  3631.1448  3667.6645  3685.0837  3631.0639   \n",
      "1    399300.SZ   20221026  3656.9027  3633.3107  3700.8797  3633.3107   \n",
      "2    399300.SZ   20221025  3627.4542  3621.9356  3670.7327  3594.7011   \n",
      "3    399300.SZ   20221024  3633.3733  3727.9150  3762.1580  3619.9876   \n",
      "4    399300.SZ   20221021  3742.8929  3753.8903  3768.6895  3724.6900   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "114  399300.SZ   20220511  3976.4231  3917.9322  4033.3026  3916.5249   \n",
      "115  399300.SZ   20220510  3919.8684  3820.6278  3932.6823  3808.5699   \n",
      "116  399300.SZ   20220509  3877.4364  3883.9514  3914.1116  3854.9353   \n",
      "117  399300.SZ   20220506  3908.8150  3928.8548  3947.2378  3902.0510   \n",
      "118  399300.SZ   20220505  4010.2102  3995.3533  4039.7000  3988.9312   \n",
      "\n",
      "     pre_close    change  pct_chg          vol       amount   dt  \\\n",
      "0    3656.9027  -25.7579  -0.7044  117998675.0  257473315.7    0   \n",
      "1    3627.4542   29.4485   0.8118  121301548.0  242453810.6    1   \n",
      "2    3633.3733   -5.9191  -0.1629  110953882.0  219302759.6    2   \n",
      "3    3742.8929 -109.5196  -2.9261  130056864.0  259450743.1    3   \n",
      "4    3754.9269  -12.0340  -0.3205   98750038.0  180686357.7    4   \n",
      "..         ...       ...      ...          ...          ...  ...   \n",
      "114  3919.8684   56.5547   1.4428  165632256.0  309294912.7  114   \n",
      "115  3877.4364   42.4320   1.0943  136416918.0  239060211.9  115   \n",
      "116  3908.8150  -31.3786  -0.8028   92936694.0  171756502.8  116   \n",
      "117  4010.2102 -101.3952  -2.5284  123005551.0  214825174.0  117   \n",
      "118  4016.2410   -6.0308  -0.1502  154170716.0  290538230.6  118   \n",
      "\n",
      "                             date  \n",
      "0   1970-01-01 00:00:00.000000000  \n",
      "1   1970-01-01 00:00:00.000000001  \n",
      "2   1970-01-01 00:00:00.000000002  \n",
      "3   1970-01-01 00:00:00.000000003  \n",
      "4   1970-01-01 00:00:00.000000004  \n",
      "..                            ...  \n",
      "114 1970-01-01 00:00:00.000000114  \n",
      "115 1970-01-01 00:00:00.000000115  \n",
      "116 1970-01-01 00:00:00.000000116  \n",
      "117 1970-01-01 00:00:00.000000117  \n",
      "118 1970-01-01 00:00:00.000000118  \n",
      "\n",
      "[119 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "baseline_df = plotter.get_baseline(\"399300.SZ\", ticket_type=TICKET_TYPE_INDEX)\n",
    "print(\"baseline_df \", baseline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e47f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============DRL Strategy Stats===========\n",
      "perf_stats_all: Annual return         -0.367943\n",
      "Cumulative returns    -0.193316\n",
      "Annual volatility      0.342544\n",
      "Sharpe ratio          -1.180400\n",
      "Calmar ratio          -1.189368\n",
      "Stability              0.660855\n",
      "Max drawdown          -0.309360\n",
      "Omega ratio            0.815873\n",
      "Sortino ratio         -1.691086\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.969158\n",
      "Daily value at risk   -0.044761\n",
      "Alpha                       NaN\n",
      "Beta                        NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats \n",
    "perf_stats_all = perf_func(returns=daily_return, factor_returns=daily_return_base, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "print(\"==============DRL Strategy Stats===========\")\n",
    "print(f\"perf_stats_all: {perf_stats_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6J0LpdE7YuQe",
   "metadata": {
    "id": "6J0LpdE7YuQe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Baseline Strategy Stats===========\n",
      "perf_stats_all: Annual return          0.234015\n",
      "Cumulative returns     0.104393\n",
      "Annual volatility      0.170323\n",
      "Sharpe ratio           1.329806\n",
      "Calmar ratio           1.700856\n",
      "Stability              0.234650\n",
      "Max drawdown          -0.137587\n",
      "Omega ratio            1.235210\n",
      "Sortino ratio          2.063975\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.289954\n",
      "Daily value at risk   -0.020560\n",
      "Alpha                  0.000000\n",
      "Beta                   1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats\n",
    "perf_stats_all = perf_func(returns=daily_return_base, factor_returns=daily_return_base, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "\n",
    "print(\"==============Baseline Strategy Stats===========\")\n",
    "\n",
    "print(f\"perf_stats_all: {perf_stats_all}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "China_A_share_market_tushare.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0492e5adbd22e67eab60cc68f6c8d46f59ec8e32b863d29391e70a96efcd66e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
